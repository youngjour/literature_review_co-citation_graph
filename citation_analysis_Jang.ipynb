{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "H34mBqkVgtfr"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Imports and Configuration\n",
        "import re\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from collections import Counter, defaultdict\n",
        "import community as community_louvain # python-louvain library\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Configuration for later analysis ---\n",
        "NUMBER_OF_TOP_ITEMS_TO_SHOW = 10 # << MODIFIED\n",
        "STOPWORDS = set([\n",
        "    \"the\", \"a\", \"an\", \"is\", \"are\", \"was\", \"were\", \"of\", \"and\", \"to\", \"in\", \"it\", \"that\", \"this\",\n",
        "    \"for\", \"on\", \"with\", \"as\", \"by\", \"at\", \"from\", \"about\", \"into\", \"onto\", \"through\", \"over\",\n",
        "    \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\",\n",
        "    \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\",\n",
        "    \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\",\n",
        "    \"don\", \"should\", \"now\", \"d\", \"ll\", \"m\", \"o\", \"re\", \"ve\", \"y\", \"ain\", \"aren\", \"couldn\",\n",
        "    \"didn\", \"doesn\", \"hadn\", \"hasn\", \"haven\", \"isn\", \"ma\", \"mightn\", \"mustn\", \"needn\", \"shan\",\n",
        "    \"shouldn\", \"wasn\", \"weren\", \"won\", \"wouldn\", \"fig\", \"figure\", \"table\", \"abstract\", \"introduction\",\n",
        "    \"results\", \"discussion\", \"conclusion\", \"references\", \"et\", \"al\", \"paper\", \"study\", \"method\",\n",
        "    \"analysis\", \"based\", \"using\", \"system\", \"approach\", \"model\", \"data\", \"research\",\n",
        "    \"urban\", \"computing\", \"city\", \"cities\", \"science\", \"review\", \"survey\", \"p\", \"pp\", \"vol\",\n",
        "    \"issue\", \"journal\", \"conference\", \"workshop\", \"chapter\", \"university\", \"department\",\n",
        "    \"institute\", \"ieee\", \"acm\", \"elsevier\", \"springer\"\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TG8YjUCyK_X",
        "outputId": "a5929df5-412a-4c83-93ae-b47e0f83ec9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully parsed 915 records from savedrecs.txt.\n",
            "\n",
            "Sample of key fields from the first parsed record:\n",
            "  TI: Urban Computing: Concepts, Methodologies, and Applications \n",
            "  AU: ['Zheng, Y', 'Capra, L', 'Wolfson, O'] ... (List of 4)\n",
            "  AF: ['Zheng, Yu', 'Capra, Licia', 'Wolfson, Ouri'] ... (List of 4)\n",
            "  PY: 2014 \n",
            "  SO: ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY \n",
            "  AB: Urbanization's rapid progress has modernized many people's lives but a ...\n",
            "  DE: ['Algorithms; Measurement; Experimentation; Urban computing; urban', 'informatics; big data; human mobility; city dynamics; urban sensing;', 'knowledge fusion; computing with heterogeneous data; trajectories']  (List of 3)\n",
            "  ID: ['PATTERNS; INFORMATION; DISCOVERY; TIME']  (List of 1)\n",
            "  CR: ['Aggarwal C. C., 2007, DATA STREAMS MODELS', 'Andrienko G., 2010, P EUR IEEE CGTC S VI', 'Andrienko N, 2003, J VISUAL LANG COMPUT, V14, P503, DOI 10.1016/S1045-926X(03)00046-6'] ... (List of 163)\n",
            "  TC: 918 \n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Parser and Initial DataFrame Processing (No significant change to logic, minor parsing robustness for authors)\n",
        "def parse_wos_file(file_content):\n",
        "    \"\"\"\n",
        "    Parses the content of a Web of Science plain text file.\n",
        "    Records are separated by 'ER' and start with 'PT J' (usually, after initial FN/VR).\n",
        "    Handles multi-line fields.\n",
        "    \"\"\"\n",
        "    records_str = file_content.split('\\nER\\n') # ER is the End Record tag\n",
        "\n",
        "    parsed_records = []\n",
        "    current_field_tag = None\n",
        "\n",
        "    for rec_str in records_str:\n",
        "        if not rec_str.strip():\n",
        "            continue\n",
        "\n",
        "        record = defaultdict(list)\n",
        "        lines = rec_str.strip().split('\\n')\n",
        "        field_tag = None\n",
        "        for line in lines:\n",
        "            if not line.strip():\n",
        "                continue\n",
        "\n",
        "            if re.match(r\"^[A-Z0-9]{2} \", line[:3]):\n",
        "                field_tag = line[:2]\n",
        "                field_value = line[3:].strip()\n",
        "            elif field_tag and line.startswith('   '):\n",
        "                field_value = line[3:].strip()\n",
        "            else:\n",
        "                if field_tag is None and ':' in line :\n",
        "                    parts = line.split(':',1)\n",
        "                    if len(parts[0]) <= 3 :\n",
        "                         field_tag = parts[0].strip()\n",
        "                         field_value = parts[1].strip()\n",
        "                    else:\n",
        "                        continue\n",
        "                else :\n",
        "                    continue\n",
        "\n",
        "            # Fields that can have multiple values and are typically semi-colon separated if on one line in source\n",
        "            # but WoS plain text often lists them on new lines with the same tag or continued lines.\n",
        "            if field_tag in ['AU', 'AF', 'DE', 'ID']: # Added 'AF' (Author Full Names)\n",
        "                record[field_tag].append(field_value)\n",
        "            elif field_tag == 'CR': # Cited References are appended individually\n",
        "                 record[field_tag].append(field_value)\n",
        "            elif field_tag in ['C1', 'RP']: # Address fields\n",
        "                if field_tag not in record or not record[field_tag]: # First line for this tag\n",
        "                    record[field_tag] = [field_value]\n",
        "                elif line.startswith('   ') and record[field_tag]: # Continuation of current C1/RP item\n",
        "                    record[field_tag][-1] += \" \" + field_value # Append to current line of the address\n",
        "                else: # New author/address block within C1 (often separated by semicolons in the file or new tag line)\n",
        "                    record[field_tag].append(field_value) # Start a new address item\n",
        "            elif field_tag == 'AB':\n",
        "                if record[field_tag]:\n",
        "                    record[field_tag] = record[field_tag] + \" \" + field_value\n",
        "                else:\n",
        "                    record[field_tag] = field_value\n",
        "            elif field_tag: # For single-value fields (or fields treated as single if not specified above)\n",
        "                if record[field_tag] and isinstance(record[field_tag], list): # If it was accidentally made a list\n",
        "                     record[field_tag][0] = field_value # Overwrite if already set (e.g. from FN on first line)\n",
        "                else:\n",
        "                    record[field_tag] = field_value\n",
        "\n",
        "\n",
        "        # Clean up: join list items for fields that are actually single\n",
        "        # For C1 and RP, if they are lists of strings, join them carefully if they represent a single address block.\n",
        "        # However, C1 can also list multiple authors' affiliations.\n",
        "        # For now, keeping C1/RP as lists of strings, where each string is a part of an address or a full one.\n",
        "        # The previous logic might have over-appended. Let's refine C1/RP handling during parsing.\n",
        "        # If C1/RP are address blocks that can legitimately be multi-part, we should join them appropriately.\n",
        "        # The defaultdict(list) and append for AU, AF, DE, ID, CR is correct.\n",
        "        # For other fields that become lists but should be strings:\n",
        "        for tag in list(record.keys()):\n",
        "            if tag not in ['AU', 'AF', 'DE', 'ID', 'CR', 'C1', 'RP'] and isinstance(record[tag], list):\n",
        "                if len(record[tag]) == 1:\n",
        "                    record[tag] = record[tag][0]\n",
        "                else: # If multiple entries for a supposedly single field, join them (heuristic)\n",
        "                    record[tag] = \"; \".join(record[tag])\n",
        "\n",
        "\n",
        "        if 'PT' in record:\n",
        "            parsed_records.append(dict(record))\n",
        "\n",
        "    return parsed_records\n",
        "\n",
        "# --- Load and parse the file ---\n",
        "file_path = \"savedrecs.txt\" # Ensure this file is in the correct path\n",
        "try:\n",
        "    with open(file_path, 'r', encoding='utf-8-sig') as f:\n",
        "        file_content = f.read()\n",
        "\n",
        "    wos_records = parse_wos_file(file_content)\n",
        "\n",
        "    if not wos_records:\n",
        "        raise ValueError(\"No records were parsed. Check file format or content.\")\n",
        "\n",
        "    df_records = pd.DataFrame(wos_records)\n",
        "\n",
        "    if 'UT' not in df_records.columns or df_records['UT'].isnull().any():\n",
        "        print(\"Warning: 'UT' field (Unique ID) is missing or incomplete. Generating sequential IDs.\")\n",
        "        df_records['UT_generated'] = range(len(df_records))\n",
        "        id_col = 'UT_generated'\n",
        "    else:\n",
        "        df_records['UT'] = df_records['UT'].astype(str).str.replace('WOS:', '', case=False)\n",
        "        id_col = 'UT'\n",
        "\n",
        "    df_records.set_index(id_col, inplace=True)\n",
        "\n",
        "    print(f\"Successfully parsed {len(df_records)} records from {file_path}.\")\n",
        "    # print(f\"DataFrame columns: {df_records.columns.tolist()}\")\n",
        "    # print(\"\\nSample of parsed data (first record C1, RP, AU, AF):\")\n",
        "    # if not df_records.empty:\n",
        "    #     sample_record = df_records.head(1)\n",
        "    #     for col_to_check in ['C1', 'RP', 'AU', 'AF', 'CR', 'DE', 'ID']:\n",
        "    #         if col_to_check in sample_record:\n",
        "    #             print(f\"{col_to_check}: {sample_record[col_to_check].values[0]}\")\n",
        "    #         else:\n",
        "    #             print(f\"{col_to_check}: Not present\")\n",
        "\n",
        "\n",
        "    # Ensure essential columns for network building exist\n",
        "    list_like_cols = ['CR', 'AU', 'AF', 'DE', 'ID'] # AF added\n",
        "    for col in list_like_cols:\n",
        "        if col not in df_records.columns:\n",
        "            df_records[col] = pd.Series([[] for _ in range(len(df_records))], index=df_records.index)\n",
        "        else:\n",
        "            # Ensure these are lists, even if NaN (for papers with no CRs, DEs, etc.)\n",
        "             df_records[col] = df_records[col].apply(lambda x: x if isinstance(x, list) else ([] if pd.isna(x) else ([x] if not isinstance(x,list) else x) ))\n",
        "\n",
        "\n",
        "    if 'TC' not in df_records.columns:\n",
        "        df_records['TC'] = 0\n",
        "    else:\n",
        "        df_records['TC'] = pd.to_numeric(df_records['TC'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "    if 'PY' not in df_records.columns:\n",
        "        df_records['PY'] = 'Unknown'\n",
        "    else:\n",
        "        df_records['PY'] = df_records['PY'].fillna('Unknown').astype(str)\n",
        "\n",
        "    if 'TI' not in df_records.columns:\n",
        "        df_records['TI'] = 'No Title Captured'\n",
        "    else:\n",
        "        df_records['TI'] = df_records['TI'].fillna('No Title Captured')\n",
        "\n",
        "    if 'SO' not in df_records.columns:\n",
        "        df_records['SO'] = 'Unknown Source'\n",
        "    else:\n",
        "        df_records['SO'] = df_records['SO'].fillna('Unknown Source')\n",
        "\n",
        "    if 'AB' not in df_records.columns:\n",
        "        df_records['AB'] = ''\n",
        "    else:\n",
        "        df_records['AB'] = df_records['AB'].fillna('')\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File '{file_path}' not found.\")\n",
        "    df_records = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during parsing or initial DataFrame processing: {e}\")\n",
        "    df_records = pd.DataFrame()\n",
        "\n",
        "# Display sample of critical fields for verification after parsing\n",
        "if not df_records.empty:\n",
        "    print(\"\\nSample of key fields from the first parsed record:\")\n",
        "    sample_record_df = df_records.head(1)\n",
        "    for col_key in ['TI', 'AU', 'AF', 'PY', 'SO', 'AB', 'DE', 'ID', 'CR', 'TC']:\n",
        "        if col_key in sample_record_df.columns:\n",
        "            val = sample_record_df[col_key].iloc[0]\n",
        "            if isinstance(val, list):\n",
        "                print(f\"  {col_key}: {val[:3]} {'...' if len(val) > 3 else ''} (List of {len(val)})\")\n",
        "            else:\n",
        "                print(f\"  {col_key}: {str(val)[:70]} {'...' if len(str(val)) > 70 else ''}\")\n",
        "        else:\n",
        "            print(f\" {col_key}: Not found\")\n",
        "else:\n",
        "    print(\"DataFrame is empty, cannot show sample.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Augh_M3ZyMgR",
        "outputId": "743d86d1-e04b-43f1-d849-8eb6593c2d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building Bibliographic Coupling Network...\n",
            "Processed bibliographic coupling for 100/915 papers...\n",
            "Processed bibliographic coupling for 200/915 papers...\n",
            "Processed bibliographic coupling for 300/915 papers...\n",
            "Processed bibliographic coupling for 400/915 papers...\n",
            "Processed bibliographic coupling for 500/915 papers...\n",
            "Processed bibliographic coupling for 600/915 papers...\n",
            "Processed bibliographic coupling for 700/915 papers...\n",
            "Processed bibliographic coupling for 800/915 papers...\n",
            "Processed bibliographic coupling for 900/915 papers...\n",
            "\n",
            "Bibliographic Coupling Network constructed:\n",
            "Number of nodes: 915\n",
            "Number of edges: 32780\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Bibliographic Coupling Network Construction\n",
        "if not df_records.empty:\n",
        "    print(\"Building Bibliographic Coupling Network...\")\n",
        "    G_coupling = nx.Graph()\n",
        "\n",
        "    for paper_id, data in df_records.iterrows():\n",
        "        # Determine the first author's name for the label (Full Name if available)\n",
        "        af_authors = data.get('AF', [])\n",
        "        au_authors = data.get('AU', [])\n",
        "        first_author_display_name = \"Unknown Author\"\n",
        "\n",
        "        if af_authors and isinstance(af_authors, list) and af_authors[0]:\n",
        "            first_author_display_name = af_authors[0]\n",
        "        elif au_authors and isinstance(au_authors, list) and au_authors[0]:\n",
        "            # Fallback to the first part of AU (before comma or semicolon) if AF is not available\n",
        "            first_author_display_name = re.split(r'[;,]', au_authors[0])[0].strip()\n",
        "\n",
        "        node_label = f\"{first_author_display_name}, {data.get('PY', 'N/A')}, {str(data.get('TI', 'No Title'))[:30]}...\"\n",
        "\n",
        "        G_coupling.add_node(\n",
        "            paper_id,\n",
        "            title=data.get('TI', 'N/A'),\n",
        "            authors_short=au_authors, # AU field\n",
        "            authors_full=af_authors,  # AF field << MODIFIED to store full names\n",
        "            year=str(data.get('PY', 'N/A')),\n",
        "            source=data.get('SO', 'N/A'),\n",
        "            times_cited=int(data.get('TC', 0)),\n",
        "            keywords_de=data.get('DE', []),\n",
        "            keywords_id=data.get('ID', []),\n",
        "            abstract=data.get('AB', ''),\n",
        "            cited_references_count=len(data.get('CR', [])),\n",
        "            label=node_label # Label now uses full first author name if available\n",
        "        )\n",
        "\n",
        "    paper_ids = list(df_records.index)\n",
        "    cited_ref_map = {pid: set(df_records.loc[pid, 'CR']) for pid in paper_ids if 'CR' in df_records.columns and isinstance(df_records.loc[pid, 'CR'], list) and df_records.loc[pid, 'CR']}\n",
        "\n",
        "\n",
        "    for i in range(len(paper_ids)):\n",
        "        for j in range(i + 1, len(paper_ids)):\n",
        "            u_id = paper_ids[i]\n",
        "            v_id = paper_ids[j]\n",
        "\n",
        "            refs_u = cited_ref_map.get(u_id, set())\n",
        "            refs_v = cited_ref_map.get(v_id, set())\n",
        "\n",
        "            if not refs_u or not refs_v:\n",
        "                continue\n",
        "\n",
        "            common_refs = refs_u.intersection(refs_v)\n",
        "            coupling_strength = len(common_refs)\n",
        "\n",
        "            if coupling_strength > 0:\n",
        "                G_coupling.add_edge(u_id, v_id, weight=coupling_strength)\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"Processed bibliographic coupling for {i+1}/{len(paper_ids)} papers...\")\n",
        "\n",
        "\n",
        "    print(f\"\\nBibliographic Coupling Network constructed:\")\n",
        "    print(f\"Number of nodes: {G_coupling.number_of_nodes()}\")\n",
        "    print(f\"Number of edges: {G_coupling.number_of_edges()}\")\n",
        "\n",
        "    if G_coupling.number_of_edges() == 0 and G_coupling.number_of_nodes() > 1:\n",
        "        print(\"\\nWarning: No edges were created. Check 'CR' field parsing and content.\")\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame `df_records` is empty. Skipping network construction.\")\n",
        "    G_coupling = nx.Graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FAfi4PCyO-j",
        "outputId": "5c44b0b0-4bdd-42b8-8682-33a5df32c91e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Analysis will proceed on the largest connected component (LCC):\n",
            "LCC - Number of nodes: 832\n",
            "LCC - Number of edges: 32779\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: Largest Connected Component (No change to logic)\n",
        "if G_coupling.number_of_nodes() > 0 and G_coupling.number_of_edges() > 0:\n",
        "    connected_components = list(nx.connected_components(G_coupling))\n",
        "    if connected_components:\n",
        "        largest_cc_nodes = max(connected_components, key=len)\n",
        "        G_main_cc_new = G_coupling.subgraph(largest_cc_nodes).copy()\n",
        "        print(f\"\\nAnalysis will proceed on the largest connected component (LCC):\")\n",
        "        print(f\"LCC - Number of nodes: {G_main_cc_new.number_of_nodes()}\")\n",
        "        print(f\"LCC - Number of edges: {G_main_cc_new.number_of_edges()}\")\n",
        "    else:\n",
        "        print(\"Graph has no connected components. Using the original graph.\")\n",
        "        G_main_cc_new = G_coupling.copy()\n",
        "else:\n",
        "    print(\"Graph G_coupling is empty or has no edges. Skipping LCC step.\")\n",
        "    G_main_cc_new = G_coupling.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRnJIw0CyQ2H",
        "outputId": "ed0903da-15aa-40ac-c7aa-593ca5a47bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating centrality measures for the LCC...\n",
            "Degree centrality calculated.\n",
            "Calculating approximate betweenness centrality with k=100...\n",
            "Approximate betweenness centrality calculated.\n",
            "Calculating eigenvector centrality...\n",
            "Eigenvector centrality calculated.\n",
            "\n",
            "Top 10 nodes in LCC by Degree Centrality:\n",
            "  1. Node Amin, Modhurima Dey, 2021, Predicting access to healthful...: 0.3213\n",
            "  2. Node Martin, Katie S., 2014, Case Study of Hartford-Connect...: 0.2972\n",
            "  3. Node Wolf-Powers, Laura, 2017, Food Deserts and Real-Estate-L...: 0.2960\n",
            "  4. Node Kelli, Heval M., 2019, With Cardiovascular Disease...: 0.2912\n",
            "  5. Node Mishra, Sabyasachee, 2023, shopping travel patterns...: 0.2876\n",
            "  6. Node Bastian, Elizabeth, 2016, Metropolitan Detroit...: 0.2864\n",
            "  7. Node Zhang, Mingyang, 2022, Urban Anomaly Analytics: Descr...: 0.2780\n",
            "  8. Node Colon-Ramos, Uriyoan, 2018, Children? A Photovoice Narrati...: 0.2720\n",
            "  9. Node Jin, He, 2021, swamps...: 0.2720\n",
            "  10. Node Cooksey-Stowers, Kristen, 2017, States...: 0.2720\n"
          ]
        }
      ],
      "source": [
        "# Cell 6: Centrality Calculations (No change to logic, label used for print will have full name)\n",
        "if G_main_cc_new.number_of_nodes() > 0:\n",
        "    print(\"\\nCalculating centrality measures for the LCC...\")\n",
        "\n",
        "    degree_centrality = nx.degree_centrality(G_main_cc_new)\n",
        "    nx.set_node_attributes(G_main_cc_new, degree_centrality, 'degree_centrality')\n",
        "    print(\"Degree centrality calculated.\")\n",
        "\n",
        "    num_nodes_for_k = G_main_cc_new.number_of_nodes()\n",
        "    k_betweenness = min(max(100, num_nodes_for_k // 20), 1000) if num_nodes_for_k > 100 else num_nodes_for_k\n",
        "    if num_nodes_for_k > 1 :\n",
        "        print(f\"Calculating approximate betweenness centrality with k={k_betweenness}...\")\n",
        "        betweenness_centrality = nx.betweenness_centrality(G_main_cc_new, k=k_betweenness, normalized=True, seed=42)\n",
        "        nx.set_node_attributes(G_main_cc_new, betweenness_centrality, 'betweenness_centrality')\n",
        "        print(\"Approximate betweenness centrality calculated.\")\n",
        "    else:\n",
        "        print(\"Skipping betweenness centrality due to very few nodes.\")\n",
        "\n",
        "    try:\n",
        "        print(\"Calculating eigenvector centrality...\")\n",
        "        eigenvector_centrality = nx.eigenvector_centrality_numpy(G_main_cc_new, weight='weight')\n",
        "        nx.set_node_attributes(G_main_cc_new, eigenvector_centrality, 'eigenvector_centrality')\n",
        "        print(\"Eigenvector centrality calculated.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not compute eigenvector centrality with weights: {e}. Trying without weights.\")\n",
        "        try:\n",
        "            eigenvector_centrality = nx.eigenvector_centrality_numpy(G_main_cc_new)\n",
        "            nx.set_node_attributes(G_main_cc_new, eigenvector_centrality, 'eigenvector_centrality')\n",
        "            print(\"Eigenvector centrality calculated (unweighted).\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Eigenvector centrality still failed: {e2}\")\n",
        "            nx.set_node_attributes(G_main_cc_new, {n: 0.0 for n in G_main_cc_new.nodes()}, 'eigenvector_centrality')\n",
        "\n",
        "    if degree_centrality:\n",
        "        sorted_degree = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
        "        # Display top N (NUMBER_OF_TOP_ITEMS_TO_SHOW) nodes\n",
        "        print(f\"\\nTop {NUMBER_OF_TOP_ITEMS_TO_SHOW} nodes in LCC by Degree Centrality:\")\n",
        "        for i, (node_id, score) in enumerate(sorted_degree[:NUMBER_OF_TOP_ITEMS_TO_SHOW]): # << MODIFIED to use global N\n",
        "            node_label = G_main_cc_new.nodes[node_id].get('label', node_id)\n",
        "            print(f\"  {i+1}. Node {node_label}: {score:.4f}\")\n",
        "else:\n",
        "    print(\"LCC is empty. Skipping centrality calculations.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edxeL31ZyTPb",
        "outputId": "a3fdb570-c288-4ced-f047-e23a0659dcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Performing community detection using Louvain algorithm on LCC...\n",
            "Using 'weight' attribute for Louvain community detection.\n",
            "Number of communities found (Louvain): 5\n",
            "\n",
            "Top 10 largest communities (Louvain):\n",
            "  Community 2: 338 nodes\n",
            "  Community 0: 329 nodes\n",
            "  Community 4: 137 nodes\n",
            "  Community 3: 20 nodes\n",
            "  Community 1: 8 nodes\n"
          ]
        }
      ],
      "source": [
        "# Cell 7: Louvain Community Detection (No change to logic)\n",
        "if G_main_cc_new.number_of_nodes() > 0 and G_main_cc_new.number_of_edges() > 0:\n",
        "    print(\"\\nPerforming community detection using Louvain algorithm on LCC...\")\n",
        "    use_weights_for_louvain = False\n",
        "    if G_main_cc_new.edges():\n",
        "        sample_edge_data = next(iter(G_main_cc_new.edges(data=True)))[2]\n",
        "        if 'weight' in sample_edge_data and isinstance(sample_edge_data['weight'], (int,float)):\n",
        "            use_weights_for_louvain = True\n",
        "            print(\"Using 'weight' attribute for Louvain community detection.\")\n",
        "        else:\n",
        "            print(\"No suitable 'weight' attribute found on edges. Running Louvain unweighted.\")\n",
        "\n",
        "    if use_weights_for_louvain:\n",
        "        partition_new = community_louvain.best_partition(G_main_cc_new, weight='weight', random_state=42)\n",
        "    else:\n",
        "        partition_new = community_louvain.best_partition(G_main_cc_new, random_state=42)\n",
        "\n",
        "    nx.set_node_attributes(G_main_cc_new, partition_new, 'community_id')\n",
        "    num_communities_found = len(set(partition_new.values()))\n",
        "    print(f\"Number of communities found (Louvain): {num_communities_found}\")\n",
        "\n",
        "    community_counts = Counter(partition_new.values())\n",
        "    # Display sizes of the N largest communities (NUMBER_OF_TOP_ITEMS_TO_SHOW, e.g. 10)\n",
        "    print(f\"\\nTop {NUMBER_OF_TOP_ITEMS_TO_SHOW} largest communities (Louvain):\") # << MODIFIED to use global N for printout\n",
        "    for i, (comm_id, count) in enumerate(community_counts.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW)):\n",
        "        print(f\"  Community {comm_id}: {count} nodes\")\n",
        "else:\n",
        "    print(\"LCC is empty or has no edges. Skipping community detection.\")\n",
        "    partition_new = {}\n",
        "    num_communities_found = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOfxtY7wyVEW",
        "outputId": "42168884-96ef-4d11-de6b-ceb1eff50515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brief Analysis of the Top 5 largest communities: [2, 0, 4, 3, 1]\n",
            "\n",
            "\n",
            "\n",
            "==================== Brief Community Analysis: ID 2 (Size: 338 papers) ====================\n",
            "\n",
            "  --- Top 10 Papers by Times Cited ---\n",
            "    1. TC: 1108 | Year: 2010 | Walker, Renee E., 2010, food deserts literature...\n",
            "    2. TC: 388 | Year: 2017 | Cooksey-Stowers, Kristen, 2017, States...\n",
            "    3. TC: 356 | Year: 2014 | Cummins, Steven, 2014, Did Not Alter Dietary Habits O...\n",
            "    4. TC: 305 | Year: 2004 | Song, Y, 2004, Measuring urban form - Is Port...\n",
            "    5. TC: 288 | Year: 2003 | Wrigley, N, 2003, deserts' study...\n",
            "    6. TC: 224 | Year: 2015 | Dubowitz, Tamara, 2015, Desert, But Not Because Of Sup...\n",
            "    7. TC: 209 | Year: 2014 | Farber, Steven, 2014, Temporal variability in transi...\n",
            "    8. TC: 189 | Year: 2008 | Hawkes, Corinna, 2008, Dietary Implications of Superm...\n",
            "    9. TC: 185 | Year: 2011 | Gordon, Cynthia, 2011, Measuring food deserts in New ...\n",
            "    10. TC: 184 | Year: 2020 | Turner, Christopher, 2020, Systematic Scoping Review...\n",
            "\n",
            "  --- Top 20 Keywords ---\n",
            "    'food': 3260\n",
            "    'access': 819\n",
            "    'desert': 698\n",
            "    'deserts': 555\n",
            "    'health': 484\n",
            "    'healthy': 404\n",
            "    'environment': 387\n",
            "    'low': 315\n",
            "    'income': 308\n",
            "    'stores': 273\n",
            "    'obesity': 270\n",
            "    'neighborhood': 255\n",
            "    'between': 245\n",
            "    'community': 245\n",
            "    'residents': 230\n",
            "    'diet': 225\n",
            "    'areas': 214\n",
            "    'associated': 211\n",
            "    'foods': 197\n",
            "    'insecurity': 197\n",
            "\n",
            "  --- Top 10 Authors ---\n",
            "    Dubowitz, Tamara: 27 appearance(s)\n",
            "    Beckman, Robin: 15 appearance(s)\n",
            "    Collins, Rebecca L.: 13 appearance(s)\n",
            "    Richardson, Andrea S.: 10 appearance(s)\n",
            "    Hunter, Gerald P.: 9 appearance(s)\n",
            "    Ghosh-Dastidar, Bonnie: 9 appearance(s)\n",
            "    Liese, Angela D.: 8 appearance(s)\n",
            "    Bell, Bethany A.: 7 appearance(s)\n",
            "    Troxel, Wendy M.: 7 appearance(s)\n",
            "    Zenk, Shannon N.: 6 appearance(s)\n",
            "\n",
            "\n",
            "==================== Brief Community Analysis: ID 0 (Size: 329 papers) ====================\n",
            "\n",
            "  --- Top 10 Papers by Times Cited ---\n",
            "    1. TC: 1193 | Year: 2015 | Zheng, Yu, 2015, Trajectory Data Mining: An Ove...\n",
            "    2. TC: 918 | Year: 2014 | Zheng, Yu, 2014, Urban Computing: Concepts, Met...\n",
            "    3. TC: 487 | Year: 2014 | Santi, Paolo, 2014, Quantifying the benefits of ve...\n",
            "    4. TC: 415 | Year: 2014 | Gabrys, Jennifer, 2014, smart city...\n",
            "    5. TC: 326 | Year: 2013 | Yuan, Nicholas Jing, 2013, T-Finder: A Recommender System...\n",
            "    6. TC: 277 | Year: 2020 | Lu, Yunlong, 2020, Computing in Urban Informatics...\n",
            "    7. TC: 253 | Year: 2014 | Su, Xing, 2014, Activity Recognition with Smar...\n",
            "    8. TC: 249 | Year: 2015 | Ma, Shuo, 2015, Real-Time City-Scale Taxi Ride...\n",
            "    9. TC: 235 | Year: 2019 | Zhang, Ke, 2019, Urban Informatics...\n",
            "    10. TC: 199 | Year: 2013 | Castro, Pablo Samuel, 2013, From Taxi GPS Traces to Social...\n",
            "\n",
            "  --- Top 20 Keywords ---\n",
            "    'smart': 313\n",
            "    'time': 246\n",
            "    'which': 243\n",
            "    'our': 211\n",
            "    'network': 191\n",
            "    'traffic': 190\n",
            "    'mobility': 190\n",
            "    'information': 189\n",
            "    'systems': 180\n",
            "    'spatial': 178\n",
            "    'proposed': 173\n",
            "    'social': 170\n",
            "    'real': 166\n",
            "    'learning': 160\n",
            "    'mobile': 160\n",
            "    'applications': 157\n",
            "    'these': 157\n",
            "    'framework': 157\n",
            "    'temporal': 152\n",
            "    'trajectory': 143\n",
            "\n",
            "  --- Top 10 Authors ---\n",
            "    Zheng, Yu: 14 appearance(s)\n",
            "    Li, Tianrui: 6 appearance(s)\n",
            "    Li, Yanhua: 6 appearance(s)\n",
            "    Cesario, Eugenio: 5 appearance(s)\n",
            "    Li, Yong: 5 appearance(s)\n",
            "    Chen, Longbiao: 5 appearance(s)\n",
            "    Silva, Thiago H.: 4 appearance(s)\n",
            "    Kaginalkar, Akshara: 4 appearance(s)\n",
            "    Gargava, Prashant: 4 appearance(s)\n",
            "    Niyogi, Dev: 4 appearance(s)\n",
            "\n",
            "\n",
            "==================== Brief Community Analysis: ID 4 (Size: 137 papers) ====================\n",
            "\n",
            "  --- Top 10 Papers by Times Cited ---\n",
            "    1. TC: 528 | Year: 2020 | Zhang, Junbo, 2020, Learning...\n",
            "    2. TC: 237 | Year: 2022 | Ali, Ahmad, 2022, for citywide traffic flows pre...\n",
            "    3. TC: 234 | Year: 2020 | Peng, Hao, 2020, flow forecasting...\n",
            "    4. TC: 200 | Year: 2020 | Du, Bowen, 2020, Flows Prediction...\n",
            "    5. TC: 180 | Year: 2020 | Xie, Peng, 2020, survey...\n",
            "    6. TC: 174 | Year: 2020 | Liu, Jia, 2020, Urban big data fusion based on...\n",
            "    7. TC: 165 | Year: 2018 | Qi, Zhongang, 2018, Fine-Grained Air Quality...\n",
            "    8. TC: 122 | Year: 2019 | Ke, Jintao, 2019, of Ride-Sourcing Services...\n",
            "    9. TC: 70 | Year: 2024 | Jin, Guangyin, 2024, Computing: A Survey...\n",
            "    10. TC: 64 | Year: 2023 | Yuan, Xiaoming, 2023, Computing Enabled Urban Traffi...\n",
            "\n",
            "  --- Top 20 Keywords ---\n",
            "    'prediction': 332\n",
            "    'temporal': 322\n",
            "    'traffic': 319\n",
            "    'learning': 239\n",
            "    'network': 228\n",
            "    'spatial': 214\n",
            "    'flow': 183\n",
            "    'graph': 176\n",
            "    'time': 154\n",
            "    'spatio': 128\n",
            "    'networks': 128\n",
            "    'neural': 122\n",
            "    'our': 112\n",
            "    'which': 112\n",
            "    'deep': 108\n",
            "    'multi': 107\n",
            "    'propose': 106\n",
            "    'models': 106\n",
            "    'real': 99\n",
            "    'proposed': 98\n",
            "\n",
            "  --- Top 10 Authors ---\n",
            "    Zheng, Yu: 12 appearance(s)\n",
            "    Zhang, Junbo: 11 appearance(s)\n",
            "    Li, Tianrui: 8 appearance(s)\n",
            "    Liang, Yuxuan: 8 appearance(s)\n",
            "    Song, Xuan: 7 appearance(s)\n",
            "    Li, Yong: 5 appearance(s)\n",
            "    Shibasaki, Ryosuke: 5 appearance(s)\n",
            "    Fan, Zipei: 5 appearance(s)\n",
            "    Wang, Hongjun: 4 appearance(s)\n",
            "    Wang, Senzhang: 4 appearance(s)\n",
            "\n",
            "\n",
            "==================== Brief Community Analysis: ID 3 (Size: 20 papers) ====================\n",
            "\n",
            "  --- Top 10 Papers by Times Cited ---\n",
            "    1. TC: 60 | Year: 2017 | Fan, Chao, 2017, Longitudinal Analysis of the O...\n",
            "    2. TC: 60 | Year: 2021 | Chakraborty, Tc, 2021, islands: A global analysis...\n",
            "    3. TC: 54 | Year: 2007 | Rigo, G., 2007, data...\n",
            "    4. TC: 45 | Year: 2018 | Bocher, Erwan, 2018, chain...\n",
            "    5. TC: 28 | Year: 2009 | Silva, Humberto R., 2009, Climate...\n",
            "    6. TC: 27 | Year: 2021 | Abir, Farhan Asaf, 2021, quantifying multivariate contr...\n",
            "    7. TC: 23 | Year: 2022 | Ramzan, Mohsin, 2022, Temperature and Land Use-Land ...\n",
            "    8. TC: 21 | Year: 2018 | Jhaldiyal, Alok, 2018, morphology...\n",
            "    9. TC: 19 | Year: 2016 | Shirowzhan, Sara, 2016, Data over Urban Areas...\n",
            "    10. TC: 11 | Year: 2023 | Alam, Irtija, 2023, Bangladesh...\n",
            "\n",
            "  --- Top 20 Keywords ---\n",
            "    'land': 32\n",
            "    'areas': 31\n",
            "    'surface': 30\n",
            "    'lst': 27\n",
            "    'heat': 26\n",
            "    'climate': 23\n",
            "    'temperature': 23\n",
            "    'area': 21\n",
            "    'rural': 21\n",
            "    'suhi': 21\n",
            "    'cover': 20\n",
            "    'effect': 20\n",
            "    'expansion': 18\n",
            "    'spatial': 17\n",
            "    'island': 17\n",
            "    'vegetation': 16\n",
            "    'between': 15\n",
            "    'difference': 15\n",
            "    'urbanization': 14\n",
            "    'index': 14\n",
            "\n",
            "  --- Top 10 Authors ---\n",
            "    Bocher, Erwan: 1 appearance(s)\n",
            "    Petit, Gwendall: 1 appearance(s)\n",
            "    Bernard, Jeremy: 1 appearance(s)\n",
            "    Palominos, Sylvain: 1 appearance(s)\n",
            "    Jhaldiyal, Alok: 1 appearance(s)\n",
            "    Gupta, Kshama: 1 appearance(s)\n",
            "    Gupta, Prasun Kumar: 1 appearance(s)\n",
            "    Thakur, Praveen: 1 appearance(s)\n",
            "    Kumar, Pramod: 1 appearance(s)\n",
            "    Ma, Xi'na: 1 appearance(s)\n",
            "\n",
            "\n",
            "==================== Brief Community Analysis: ID 1 (Size: 8 papers) ====================\n",
            "\n",
            "  --- Top 10 Papers by Times Cited ---\n",
            "    1. TC: 46 | Year: 2021 | Zeng, Zhiqiang, 2021, provide decision support for r...\n",
            "    2. TC: 41 | Year: 2017 | Hua, Lizhong, 2017, application associated with ra...\n",
            "    3. TC: 41 | Year: 2006 | Jenerette, G. Darrel, 2006, provisioning of urban freshwat...\n",
            "    4. TC: 24 | Year: 2007 | Bennis, S., 2007, New runoff simulation model fo...\n",
            "    5. TC: 13 | Year: 2007 | Crobeddu, E., 2007, Improved rational hydrograph m...\n",
            "    6. TC: 12 | Year: 2020 | Li, Donglai, 2020, Urban Flood...\n",
            "    7. TC: 0 | Year: 2025 | Chen, Tong, 2025, partitioning techniques and pa...\n",
            "    8. TC: 0 | Year: 2025 | Sheng, Zheng, 2025, Real-Time Waterlogging Monitor...\n",
            "\n",
            "  --- Top 20 Keywords ---\n",
            "    'runoff': 16\n",
            "    'rational': 15\n",
            "    'proposed': 13\n",
            "    'hydrograph': 13\n",
            "    'time': 12\n",
            "    'management': 12\n",
            "    'real': 12\n",
            "    'era': 11\n",
            "    'water': 11\n",
            "    'swmm': 11\n",
            "    'performance': 10\n",
            "    'drainage': 10\n",
            "    'ecosystem': 10\n",
            "    'waterlogging': 10\n",
            "    'areas': 9\n",
            "    'improved': 9\n",
            "    'web': 9\n",
            "    'models': 8\n",
            "    'ecological': 8\n",
            "    'new': 7\n",
            "\n",
            "  --- Top 10 Authors ---\n",
            "    Bennis, S.: 2 appearance(s)\n",
            "    Crobeddu, E.: 2 appearance(s)\n",
            "    Li, Donglai: 1 appearance(s)\n",
            "    Hou, Jingming: 1 appearance(s)\n",
            "    Xia, Junqiang: 1 appearance(s)\n",
            "    Tong, Yu: 1 appearance(s)\n",
            "    Yang, Dong: 1 appearance(s)\n",
            "    Zhang, Dawei: 1 appearance(s)\n",
            "    Gao, Xujun: 1 appearance(s)\n",
            "    Chen, Tong: 1 appearance(s)\n",
            "\n",
            "\n",
            "==================== End of Brief Top 5 Community Analysis ====================\n"
          ]
        }
      ],
      "source": [
        "# Cell 8: Initial Community Analysis Printout (Modified to use full author names and NUMBER_OF_TOP_ITEMS_TO_SHOW)\n",
        "# This cell provides a basic printout. The more detailed one is in Cell 10.\n",
        "\n",
        "def get_node_data_for_initial_analysis(graph, node_id): # Renamed to avoid conflict\n",
        "    if node_id not in graph:\n",
        "        return {\"id\": node_id, \"error\": \"Node not found in graph\"}\n",
        "    node_attrs = graph.nodes[node_id]\n",
        "\n",
        "    # Prioritize full author names, fallback to short names\n",
        "    authors_list = node_attrs.get('authors_full', [])\n",
        "    if not authors_list or not any(authors_list): # If AF is empty or list of empty/None\n",
        "        authors_list = node_attrs.get('authors_short', [])\n",
        "\n",
        "    title_text = node_attrs.get('title', '')\n",
        "    abstract_text = node_attrs.get('abstract', '')\n",
        "    keywords_de_list = node_attrs.get('keywords_de', [])\n",
        "    keywords_id_list = node_attrs.get('keywords_id', [])\n",
        "    keywords_de_str = \" \".join(keywords_de_list if isinstance(keywords_de_list, list) else [str(keywords_de_list)])\n",
        "    keywords_id_str = \" \".join(keywords_id_list if isinstance(keywords_id_list, list) else [str(keywords_id_list)])\n",
        "    text_for_keywords = f\"{title_text} {abstract_text} {keywords_de_str} {keywords_id_str}\"\n",
        "\n",
        "    return {\n",
        "        \"id\": node_id,\n",
        "        \"label\": node_attrs.get('label', str(node_id)), # Label already updated for full first author\n",
        "        \"text_for_keywords\": text_for_keywords,\n",
        "        \"year\": node_attrs.get('year', 'N/A'),\n",
        "        \"times_cited\": int(node_attrs.get('times_cited', 0)),\n",
        "        \"authors\": authors_list, # << MODIFIED to use full names primarily\n",
        "        \"source\": node_attrs.get('source', 'N/A'),\n",
        "        \"degree_centrality\": float(node_attrs.get('degree_centrality', 0.0)),\n",
        "        \"betweenness_centrality\": float(node_attrs.get('betweenness_centrality', 0.0)),\n",
        "        \"eigenvector_centrality\": float(node_attrs.get('eigenvector_centrality', 0.0)),\n",
        "        \"community_id\": node_attrs.get('community_id', -1)\n",
        "    }\n",
        "\n",
        "if 'partition_new' not in locals() or not isinstance(partition_new, dict) or not partition_new:\n",
        "    print(\"ERROR: 'partition_new' dictionary not found or empty.\")\n",
        "elif 'G_main_cc_new' not in locals() or not hasattr(G_main_cc_new, 'nodes') or G_main_cc_new.number_of_nodes() == 0:\n",
        "    print(\"ERROR: 'G_main_cc_new' graph not found or empty.\")\n",
        "else:\n",
        "    community_sizes = Counter(partition_new.values())\n",
        "    # Analyze top N (NUMBER_OF_TOP_ITEMS_TO_SHOW) largest communities\n",
        "    top_communities_to_analyze = community_sizes.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW) # << MODIFIED\n",
        "\n",
        "    if not top_communities_to_analyze:\n",
        "        print(\"No communities found to analyze.\")\n",
        "    else:\n",
        "        top_community_ids_to_analyze = [item[0] for item in top_communities_to_analyze]\n",
        "        print(f\"Brief Analysis of the Top {len(top_community_ids_to_analyze)} largest communities: {top_community_ids_to_analyze}\\n\")\n",
        "\n",
        "        for comm_id in top_community_ids_to_analyze:\n",
        "            community_size = community_sizes[comm_id]\n",
        "            print(f\"\\n\\n{'='*20} Brief Community Analysis: ID {comm_id} (Size: {community_size} papers) {'='*20}\")\n",
        "            community_node_ids = [node_id for node_id, c_id in partition_new.items() if c_id == comm_id]\n",
        "            community_papers_details = []\n",
        "            for node_id in community_node_ids:\n",
        "                paper_data = get_node_data_for_initial_analysis(G_main_cc_new, node_id)\n",
        "                if \"error\" not in paper_data:\n",
        "                     community_papers_details.append(paper_data)\n",
        "\n",
        "            if not community_papers_details:\n",
        "                print(\"  No valid paper data collected for this community.\")\n",
        "                continue\n",
        "\n",
        "            sorted_by_times_cited = sorted(community_papers_details, key=lambda x: x['times_cited'], reverse=True)\n",
        "            print(f\"\\n  --- Top {NUMBER_OF_TOP_ITEMS_TO_SHOW} Papers by Times Cited ---\")\n",
        "            for i, paper in enumerate(sorted_by_times_cited[:NUMBER_OF_TOP_ITEMS_TO_SHOW]):\n",
        "                print(f\"    {i+1}. TC: {paper['times_cited']} | Year: {paper['year']} | {paper['label']}\")\n",
        "\n",
        "            # ... (other brief centrality rankings if desired, using NUMBER_OF_TOP_ITEMS_TO_SHOW)\n",
        "\n",
        "            all_text_content_in_community = [paper['text_for_keywords'] for paper in community_papers_details if paper['text_for_keywords']]\n",
        "            community_words = []\n",
        "            for text_content in all_text_content_in_community:\n",
        "                words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text_content.lower())\n",
        "                community_words.extend([word for word in words if word not in STOPWORDS and len(word) > 2])\n",
        "            keyword_counts = Counter(community_words)\n",
        "            print(f\"\\n  --- Top {NUMBER_OF_TOP_ITEMS_TO_SHOW * 2} Keywords ---\") # Shows more keywords\n",
        "            for keyword, count in keyword_counts.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW * 2): print(f\"    '{keyword}': {count}\")\n",
        "\n",
        "            all_authors_in_community = []\n",
        "            for paper in community_papers_details:\n",
        "                if paper['authors']: all_authors_in_community.extend(paper['authors'])\n",
        "            author_counts = Counter(all_authors_in_community)\n",
        "            print(f\"\\n  --- Top {NUMBER_OF_TOP_ITEMS_TO_SHOW} Authors ---\") # Uses full names now\n",
        "            for author, count in author_counts.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW): print(f\"    {author}: {count} appearance(s)\")\n",
        "        print(f\"\\n\\n{'='*20} End of Brief Top {len(top_community_ids_to_analyze)} Community Analysis {'='*20}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14ittWAfyWlr",
        "outputId": "17956748-2390-431d-b896-75f89f6a576c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating Detailed Print Summaries for Top 5 Communities: [2, 0, 4, 3, 1]\n",
            "\n",
            "\n",
            "\n",
            "============================== Detailed Print Summary: Community ID 2 (Size: 338 papers) ==============================\n",
            "\n",
            "   **Temporal Overview:**\n",
            "     - Years Covered: 2002 - 2025\n",
            "     - Median Year: 2019\n",
            "\n",
            "   **Top 10 Papers by Times Cited (with Abstracts):**\n",
            "    1. **Paper:** Walker, Renee E., 2010, food deserts literature...\n",
            "       **Authors:** Walker, Renee E., Keane, Christopher R., Burke, Jessica G.\n",
            "       **Year:** 2010, **Times Cited:** 1108\n",
            "       **Source:** HEALTH & PLACE\n",
            "       **Abstract:** Increasingly, studies are focusing on the role the local food environment plays in residents' ability to purchase affordable, healthy and nutritious foods. In a food desert, an area devoid of a supermarket, access to healthy food is limited. We conducted a systematic review of studies that focused on food access and food desert research in the United States. The 31 studies identified utilized 9 measures to assess food access. Results from these studies can be summarized primarily into four major...\n",
            "\n",
            "    2. **Paper:** Cooksey-Stowers, Kristen, 2017, States...\n",
            "       **Authors:** Cooksey-Stowers, Kristen, Schwartz, Marlene B., Brownell, Kelly D.\n",
            "       **Year:** 2017, **Times Cited:** 388\n",
            "       **Source:** INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH\n",
            "       **Abstract:** This paper investigates the effect of food environments, characterized as food swamps, on adult obesity rates. Food swamps have been described as areas with a high-density of establishments selling high-calorie fast food and junk food, relative to healthier food options. This study examines multiple ways of categorizing food environments as food swamps and food deserts, including alternate versions of the Retail Food Environment Index. We merged food outlet, sociodemographic and obesity data fro...\n",
            "\n",
            "    3. **Paper:** Cummins, Steven, 2014, Did Not Alter Dietary Habits O...\n",
            "       **Authors:** Cummins, Steven, Flint, Ellen, Matthews, Stephen A.\n",
            "       **Year:** 2014, **Times Cited:** 356\n",
            "       **Source:** HEALTH AFFAIRS\n",
            "       **Abstract:** National and local policies to improve diet in low-income US populations include increasing physical access to grocery stores and supermarkets in underserved neighborhoods. In a pilot study that evaluated the impacts of opening a new supermarket in a Philadelphia community considered a \"food desert\"-part of the Pennsylvania Fresh Food Financing Initiative-we found that the intervention moderately improved residents' perceptions of food accessibility. However, it did not lead to changes in report...\n",
            "\n",
            "    4. **Paper:** Song, Y, 2004, Measuring urban form - Is Port...\n",
            "       **Authors:** Song, Y, Knaap, GJ\n",
            "       **Year:** 2004, **Times Cited:** 305\n",
            "       **Source:** JOURNAL OF THE AMERICAN PLANNING ASSOCIATION\n",
            "       **Abstract:** Although many have written about urban sprawl, few have sought to measure it. In this article, we present several quantitative measures of urban form and compute these for neighborhoods of varying age in Washington County, the western portion of the Portland, Oregon, metropolitan area. Our results suggest (1) neighborhoods in Washington County have increased in single-family dwelling unit density since the 1960s; (2) internal street connectivity and pedestrian access to commercial areas and bus ...\n",
            "\n",
            "    5. **Paper:** Wrigley, N, 2003, deserts' study...\n",
            "       **Authors:** Wrigley, N, Warm, D, Margetts, B\n",
            "       **Year:** 2003, **Times Cited:** 288\n",
            "       **Source:** ENVIRONMENT AND PLANNING A\n",
            "       **Abstract:** Within a context of public policy debate in the United Kingdom on social exclusion, health inequalities, and food poverty, the metaphor of the 'food desert' caught the imagination of those involved in policy development. Drawing from a major cross-disciplinary investigation of food access and food poverty in British cities, the authors report in this paper findings from the first 'before/after' study of food consumption in a highly deprived area of a British city experiencing a sudden and signif...\n",
            "\n",
            "    6. **Paper:** Dubowitz, Tamara, 2015, Desert, But Not Because Of Sup...\n",
            "       **Authors:** Dubowitz, Tamara, Ghosh-Dastidar, Madhumita, Cohen, Deborah A. et al.\n",
            "       **Year:** 2015, **Times Cited:** 224\n",
            "       **Source:** HEALTH AFFAIRS\n",
            "       **Abstract:** Placing full-service supermarkets in food deserts-areas with limited access to healthy food-has been promoted as a way to reduce inequalities in access to healthy food, improve diet, and reduce the risk of obesity. However, previous studies provide scant evidence of such impacts. We surveyed households in two Pittsburgh, Pennsylvania, neighborhoods in 2011 and 2014, one of which received a new supermarket in 2013. Comparing trends in the two neighborhoods, we obtained evidence of multiple positi...\n",
            "\n",
            "    7. **Paper:** Farber, Steven, 2014, Temporal variability in transi...\n",
            "       **Authors:** Farber, Steven, Morang, Melinda Z., Widener, Michael J.\n",
            "       **Year:** 2014, **Times Cited:** 209\n",
            "       **Source:** APPLIED GEOGRAPHY\n",
            "       **Abstract:** Food desert studies attempt to identify geographic areas in which people lack access to sources of healthy food. While academic and policy research often defines access to food stores using simple Euclidean distance or road network metrics, dense urban areas with large public transit systems call for more sophisticated methods of determining access. It is particularly important to understand the level of access the transit-dependent population has to healthy food vendors, as their mobility is la...\n",
            "\n",
            "    8. **Paper:** Hawkes, Corinna, 2008, Dietary Implications of Superm...\n",
            "       **Authors:** Hawkes, Corinna\n",
            "       **Year:** 2008, **Times Cited:** 189\n",
            "       **Source:** DEVELOPMENT POLICY REVIEW\n",
            "       **Abstract:** Five decisions by supermarket operators have important dietary implications: the location of their outlets: the foods they sell; the prices they charge; the promotional strategies they use; and the nutrition-related activities they implement. These decisions influence food accessibility, availability, prices and desirability, which in turn influence the decisions consumers make about food. Based on a comprehensive literature review, this article finds that the dietary implications are both posit...\n",
            "\n",
            "    9. **Paper:** Gordon, Cynthia, 2011, Measuring food deserts in New ...\n",
            "       **Authors:** Gordon, Cynthia, Purciel-Hill, Marnie, Ghai, Nirupa R. et al.\n",
            "       **Year:** 2011, **Times Cited:** 185\n",
            "       **Source:** HEALTH & PLACE\n",
            "       **Abstract:** There has been growing interest in the environmental factors that contribute to poor health outcomes, particularly in areas where health disparities are pronounced. The locations of food deserts, or unhealthy food environments, correspond to areas with the highest proportions of African-American/Black residents, a population suffering from higher rates of many chronic conditions, including obesity and diabetes in our study area. This study seeks to enhance our understanding of the role of the ne...\n",
            "\n",
            "    10. **Paper:** Turner, Christopher, 2020, Systematic Scoping Review...\n",
            "       **Authors:** Turner, Christopher, Kalamatianou, Sofia, Drewnowski, Adam et al.\n",
            "       **Year:** 2020, **Times Cited:** 184\n",
            "       **Source:** ADVANCES IN NUTRITION\n",
            "       **Abstract:** Food environment research is increasingly gaining prominence in low- and middle-income countries (LMICs). However, in the absence of a systematic review of the literature, little is known about the emerging body of evidence from these settings. This systematic scoping review aims to address this gap. A systematic search of 6 databases was conducted in December 2017 and retrieved 920 records. In total, 70 peer-reviewed articles met the eligibility criteria and were included. Collectively, article...\n",
            "\n",
            "\n",
            "   **Suggested Theme:** Food, Access, Desert\n",
            "\n",
            "   **Top 20 Keywords:**\n",
            "     - 'food': 3260\n",
            "     - 'access': 819\n",
            "     - 'desert': 698\n",
            "     - 'deserts': 555\n",
            "     - 'health': 484\n",
            "     - 'healthy': 404\n",
            "     - 'environment': 387\n",
            "     - 'low': 315\n",
            "     - 'income': 308\n",
            "     - 'stores': 273\n",
            "     - 'obesity': 270\n",
            "     - 'neighborhood': 255\n",
            "     - 'between': 245\n",
            "     - 'community': 245\n",
            "     - 'residents': 230\n",
            "     - 'diet': 225\n",
            "     - 'areas': 214\n",
            "     - 'associated': 211\n",
            "     - 'foods': 197\n",
            "     - 'insecurity': 197\n",
            "\n",
            "   **Top 10 Authors:**\n",
            "     - Dubowitz, Tamara: 27 paper(s)/appearance(s)\n",
            "     - Beckman, Robin: 15 paper(s)/appearance(s)\n",
            "     - Collins, Rebecca L.: 13 paper(s)/appearance(s)\n",
            "     - Richardson, Andrea S.: 10 paper(s)/appearance(s)\n",
            "     - Hunter, Gerald P.: 9 paper(s)/appearance(s)\n",
            "     - Ghosh-Dastidar, Bonnie: 9 paper(s)/appearance(s)\n",
            "     - Liese, Angela D.: 8 paper(s)/appearance(s)\n",
            "     - Bell, Bethany A.: 7 paper(s)/appearance(s)\n",
            "     - Troxel, Wendy M.: 7 paper(s)/appearance(s)\n",
            "     - Zenk, Shannon N.: 6 paper(s)/appearance(s)\n",
            "\n",
            "\n",
            "============================== Detailed Print Summary: Community ID 0 (Size: 329 papers) ==============================\n",
            "\n",
            "   **Temporal Overview:**\n",
            "     - Years Covered: 2006 - 2025\n",
            "     - Median Year: 2020\n",
            "\n",
            "   **Top 10 Papers by Times Cited (with Abstracts):**\n",
            "    1. **Paper:** Zheng, Yu, 2015, Trajectory Data Mining: An Ove...\n",
            "       **Authors:** Zheng, Yu\n",
            "       **Year:** 2015, **Times Cited:** 1193\n",
            "       **Source:** ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY\n",
            "       **Abstract:** The advances in location-acquisition and mobile computing techniques have generated massive spatial trajectory data, which represent the mobility of a diversity of moving objects, such as people, vehicles, and animals. Many techniques have been proposed for processing, managing, and mining trajectory data in the past decade, fostering a broad range of applications. In this article, we conduct a systematic survey on the major research into trajectory data mining, providing a panorama of the field...\n",
            "\n",
            "    2. **Paper:** Zheng, Yu, 2014, Urban Computing: Concepts, Met...\n",
            "       **Authors:** Zheng, Yu, Capra, Licia, Wolfson, Ouri et al.\n",
            "       **Year:** 2014, **Times Cited:** 918\n",
            "       **Source:** ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY\n",
            "       **Abstract:** Urbanization's rapid progress has modernized many people's lives but also engendered big issues, such as traffic congestion, energy consumption, and pollution. Urban computing aims to tackle these issues by using the data that has been generated in cities (e.g., traffic flow, human mobility, and geographical data). Urban computing connects urban sensing, data management, data analytics, and service providing into a recurrent process for an unobtrusive and continuous improvement of people's lives...\n",
            "\n",
            "    3. **Paper:** Santi, Paolo, 2014, Quantifying the benefits of ve...\n",
            "       **Authors:** Santi, Paolo, Resta, Giovanni, Szell, Michael et al.\n",
            "       **Year:** 2014, **Times Cited:** 487\n",
            "       **Source:** AMERICA\n",
            "       **Abstract:** Taxi services are a vital part of urban transportation, and a considerable contributor to traffic congestion and air pollution causing substantial adverse effects on human health. Sharing taxi trips is a possible way of reducing the negative impact of taxi services on cities, but this comes at the expense of passenger discomfort quantifiable in terms of a longer travel time. Due to computational challenges, taxi sharing has traditionally been approached on small scales, such as within airport pe...\n",
            "\n",
            "    4. **Paper:** Gabrys, Jennifer, 2014, smart city...\n",
            "       **Authors:** Gabrys, Jennifer\n",
            "       **Year:** 2014, **Times Cited:** 415\n",
            "       **Source:** ENVIRONMENT AND PLANNING D-SOCIETY & SPACE\n",
            "       **Abstract:** A new wave of smart-city projects is underway that proposes to deploy sensor-based ubiquitous computing across urban infrastructures and mobile devices to achieve greater sustainability. But in what ways do these smart and sustainable cities give rise to distinct material-political arrangements and practices that potentially delimit urban 'citizenship' to a series of actions focused on monitoring and managing data? And what are the implications of computationally organized distributions of envir...\n",
            "\n",
            "    5. **Paper:** Yuan, Nicholas Jing, 2013, T-Finder: A Recommender System...\n",
            "       **Authors:** Yuan, Nicholas Jing, Zheng, Yu, Zhang, Liuhang et al.\n",
            "       **Year:** 2013, **Times Cited:** 326\n",
            "       **Source:** IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\n",
            "       **Abstract:** This paper presents a recommender system for both taxi drivers and people expecting to take a taxi, using the knowledge of 1) passengers' mobility patterns and 2) taxi drivers' picking-up/dropping-off behaviors learned from the GPS trajectories of taxicabs. First, this recommender system provides taxi drivers with some locations and the routes to these locations, toward which they are more likely to pick up passengers quickly (during the routes or in these locations) and maximize the profit of t...\n",
            "\n",
            "    6. **Paper:** Lu, Yunlong, 2020, Computing in Urban Informatics...\n",
            "       **Authors:** Lu, Yunlong, Huang, Xiaohong, Dai, Yueyue et al.\n",
            "       **Year:** 2020, **Times Cited:** 277\n",
            "       **Source:** IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS\n",
            "       **Abstract:** Driven by technologies such as mobile edge computing and 5G, recent years have witnessed the rapid development of urban informatics, where a large amount of data is generated. To cope with the growing data, artificial intelligence algorithms have been widely exploited. Federated learning is a promising paradigm for distributed edge computing, which enables edge nodes to train models locally without transmitting their data to a server. However, the security and privacy concerns of federated learn...\n",
            "\n",
            "    7. **Paper:** Su, Xing, 2014, Activity Recognition with Smar...\n",
            "       **Authors:** Su, Xing, Tong, Hanghang, Ji, Ping\n",
            "       **Year:** 2014, **Times Cited:** 253\n",
            "       **Source:** TSINGHUA SCIENCE AND TECHNOLOGY\n",
            "       **Abstract:** The ubiquity of smartphones together with their ever-growing computing, networking, and sensing powers have been changing the landscape of people's daily life. Among others, activity recoginition, which takes the raw sensor reading as inputs and predicts a user's motion activity, has become an active research area in recent years. It is the core building block in many high-impact applications, ranging from health and fitness monitoring, personal biometric signature, urban computing, assistive te...\n",
            "\n",
            "    8. **Paper:** Ma, Shuo, 2015, Real-Time City-Scale Taxi Ride...\n",
            "       **Authors:** Ma, Shuo, Zheng, Yu, Wolfson, Ouri\n",
            "       **Year:** 2015, **Times Cited:** 249\n",
            "       **Source:** IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\n",
            "       **Abstract:** We proposed and developed a taxi-sharing system that accepts taxi passengers' real-time ride requests sent from smartphones and schedules proper taxis to pick up them via ridesharing, subject to time, capacity, and monetary constraints. The monetary constraints provide incentives for both passengers and taxi drivers: passengers will not pay more compared with no ridesharing and get compensated if their travel time is lengthened due to ridesharing; taxi drivers will make money for all the detour ...\n",
            "\n",
            "    9. **Paper:** Zhang, Ke, 2019, Urban Informatics...\n",
            "       **Authors:** Zhang, Ke, Zhu, Yongxu, Leng, Supeng et al.\n",
            "       **Year:** 2019, **Times Cited:** 235\n",
            "       **Source:** IEEE INTERNET OF THINGS JOURNAL\n",
            "       **Abstract:** Led by industrialization of smart cities, numerous interconnected mobile devices, and novel applications have emerged in the urban environment, providing great opportunities to realize industrial automation. In this context, autonomous driving is an attractive issue, which leverages large amounts of sensory information for smart navigation while posing intensive computation demands on resource constrained vehicles. Mobile edge computing (MEC) is a potential solution to alleviate the heavy burden...\n",
            "\n",
            "    10. **Paper:** Castro, Pablo Samuel, 2013, From Taxi GPS Traces to Social...\n",
            "       **Authors:** Castro, Pablo Samuel, Zhang, Daqing, Chen, Chao et al.\n",
            "       **Year:** 2013, **Times Cited:** 199\n",
            "       **Source:** ACM COMPUTING SURVEYS\n",
            "       **Abstract:** Vehicles equipped with GPS localizers are an important sensory device for examining people's movements and activities. Taxis equipped with GPS localizers serve the transportation needs of a large number of people driven by diverse needs; their traces can tell us where passengers were picked up and dropped off, which route was taken, and what steps the driver took to find a new passenger. In this article, we provide an exhaustive survey of the work on mining these traces. We first provide a forma...\n",
            "\n",
            "\n",
            "   **Suggested Theme:** Smart, Time, Which\n",
            "\n",
            "   **Top 20 Keywords:**\n",
            "     - 'smart': 313\n",
            "     - 'time': 246\n",
            "     - 'which': 243\n",
            "     - 'our': 211\n",
            "     - 'network': 191\n",
            "     - 'traffic': 190\n",
            "     - 'mobility': 190\n",
            "     - 'information': 189\n",
            "     - 'systems': 180\n",
            "     - 'spatial': 178\n",
            "     - 'proposed': 173\n",
            "     - 'social': 170\n",
            "     - 'real': 166\n",
            "     - 'learning': 160\n",
            "     - 'mobile': 160\n",
            "     - 'applications': 157\n",
            "     - 'these': 157\n",
            "     - 'framework': 157\n",
            "     - 'temporal': 152\n",
            "     - 'trajectory': 143\n",
            "\n",
            "   **Top 10 Authors:**\n",
            "     - Zheng, Yu: 14 paper(s)/appearance(s)\n",
            "     - Li, Tianrui: 6 paper(s)/appearance(s)\n",
            "     - Li, Yanhua: 6 paper(s)/appearance(s)\n",
            "     - Cesario, Eugenio: 5 paper(s)/appearance(s)\n",
            "     - Li, Yong: 5 paper(s)/appearance(s)\n",
            "     - Chen, Longbiao: 5 paper(s)/appearance(s)\n",
            "     - Silva, Thiago H.: 4 paper(s)/appearance(s)\n",
            "     - Kaginalkar, Akshara: 4 paper(s)/appearance(s)\n",
            "     - Gargava, Prashant: 4 paper(s)/appearance(s)\n",
            "     - Niyogi, Dev: 4 paper(s)/appearance(s)\n",
            "\n",
            "\n",
            "============================== Detailed Print Summary: Community ID 4 (Size: 137 papers) ==============================\n",
            "\n",
            "   **Temporal Overview:**\n",
            "     - Years Covered: 2014 - 2025\n",
            "     - Median Year: 2023\n",
            "\n",
            "   **Top 10 Papers by Times Cited (with Abstracts):**\n",
            "    1. **Paper:** Zhang, Junbo, 2020, Learning...\n",
            "       **Authors:** Zhang, Junbo, Zheng, Yu, Sun, Junkai et al.\n",
            "       **Year:** 2020, **Times Cited:** 528\n",
            "       **Source:** IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\n",
            "       **Abstract:** Predicting flows (e.g., the traffic of vehicles, crowds, and bikes), consisting of the in-out traffic at a node and transitions between different nodes, in a spatio-temporal network plays an important role in transportation systems. However, this is a very challenging problem, affected by multiple complex factors, such as the spatial correlation between different locations, temporal correlation among different time intervals, and external factors (like events and weather). In addition, the flow ...\n",
            "\n",
            "    2. **Paper:** Ali, Ahmad, 2022, for citywide traffic flows pre...\n",
            "       **Authors:** Ali, Ahmad, Zhu, Yanmin, Zakarya, Muhammad\n",
            "       **Year:** 2022, **Times Cited:** 237\n",
            "       **Source:** NEURAL NETWORKS\n",
            "       **Abstract:** The prediction of crowd flows is an important urban computing issue whose purpose is to predict the future number of incoming and outgoing people in regions. Measuring the complicated spatial-temporal dependencies with external factors, such as weather conditions and surrounding point-of-interest (POI) distribution is the most difficult aspect of predicting crowd flows movement. To overcome the above issue, this paper advises a unified dynamic deep spatio-temporal neural network model based on c...\n",
            "\n",
            "    3. **Paper:** Peng, Hao, 2020, flow forecasting...\n",
            "       **Authors:** Peng, Hao, Wang, Hongfei, Du, Bowen et al.\n",
            "       **Year:** 2020, **Times Cited:** 234\n",
            "       **Source:** INFORMATION SCIENCES\n",
            "       **Abstract:** Accurate and real-time traffic passenger flows forecasting at transportation hubs, such as subway/bus stations, is a practical application and of great significance for urban traffic planning, control, guidance, etc. Recently deep learning based methods are promised to learn the spatial-temporal features from high non-linearity and complexity of traffic flows. However, it is still very challenging to handle so much complex factors including the urban transportation network topological structures...\n",
            "\n",
            "    4. **Paper:** Du, Bowen, 2020, Flows Prediction...\n",
            "       **Authors:** Du, Bowen, Peng, Hao, Wang, Senzhang et al.\n",
            "       **Year:** 2020, **Times Cited:** 200\n",
            "       **Source:** IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS\n",
            "       **Abstract:** Urban traffic passenger flows prediction is practically important to facilitate many real applications including transportation management and public safety. Recently, deep learning based approaches are proposed to learn the spatio-temporal characteristics of the traffic passenger flows. However, it is still very challenging to handle some complex factors such as hybrid transportation lines, mixed traffic, transfer stations, and some extreme weathers. Considering the multi-channel and irregulari...\n",
            "\n",
            "    5. **Paper:** Xie, Peng, 2020, survey...\n",
            "       **Authors:** Xie, Peng, Li, Tianrui, Liu, Jia et al.\n",
            "       **Year:** 2020, **Times Cited:** 180\n",
            "       **Source:** INFORMATION FUSION\n",
            "       **Abstract:** Urban spatiotemporal flow prediction is of great importance to traffic management, land use, public safety. This prediction task is affected by several complex and dynamic factors, such as patterns of human activities, weather, events, and holidays. Datasets evaluated the flow come from various sources in different domains, e.g. mobile phone data, taxi trajectories data, metro/bus swiping data, bike-sharing data. To summarize these methodologies of urban flow prediction, in this paper, we first ...\n",
            "\n",
            "    6. **Paper:** Liu, Jia, 2020, Urban big data fusion based on...\n",
            "       **Authors:** Liu, Jia, Li, Tianrui, Xie, Peng et al.\n",
            "       **Year:** 2020, **Times Cited:** 174\n",
            "       **Source:** INFORMATION FUSION\n",
            "       **Abstract:** Urban big data fusion creates huge values for urban computing in solving urban problems. In recent years, various models and algorithms based on deep learning have been proposed to unlock the power of knowledge from urban big data. To clarify the methodologies of urban big data fusion based on deep learning (DL), this paper classifies them into three categories: DL-output-based fusion, DL-input-based fusion and DL-double-stage-based fusion. These methods use deep learning to learn feature repres...\n",
            "\n",
            "    7. **Paper:** Qi, Zhongang, 2018, Fine-Grained Air Quality...\n",
            "       **Authors:** Qi, Zhongang, Wang, Tianchun, Song, Guojie et al.\n",
            "       **Year:** 2018, **Times Cited:** 165\n",
            "       **Source:** IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\n",
            "       **Abstract:** The interpolation, prediction, and feature analysis of fine-gained air quality are three important topics in the area of urban air computing. The solutions to these topics can provide extremely useful information to support air pollution control, and consequently generate great societal and technical impacts. Most of the existing work solves the three problems separately by different models. In this paper, we propose a general and effective approach to solve the three problems in one model calle...\n",
            "\n",
            "    8. **Paper:** Ke, Jintao, 2019, of Ride-Sourcing Services...\n",
            "       **Authors:** Ke, Jintao, Yang, Hai, Zheng, Hongyu et al.\n",
            "       **Year:** 2019, **Times Cited:** 122\n",
            "       **Source:** IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS\n",
            "       **Abstract:** Ride-sourcing services are becoming an increasingly popular transportation mode in cities all over the world. With real-time information from both drivers and passengers, the ride-sourcing platform can reduce matching frictions and improve efficiencies by surge pricing, optimal vehicle-trip assignment, and proactive ridesplitting strategies. An important foundation of these strategies is the short-term supply-demand forecasting. In this paper, we tackle the problem of predicting the short-term s...\n",
            "\n",
            "    9. **Paper:** Jin, Guangyin, 2024, Computing: A Survey...\n",
            "       **Authors:** Jin, Guangyin, Liang, Yuxuan, Fang, Yuchen et al.\n",
            "       **Year:** 2024, **Times Cited:** 70\n",
            "       **Source:** IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING\n",
            "       **Abstract:** With recent advances in sensing technologies, a myriad of spatio-temporal data has been generated and recorded in smart cities. Forecasting the evolution patterns of spatio-temporal data is an important yet demanding aspect of urban computing, which can enhance intelligent management decisions in various fields, including transportation, environment, climate, public safety, healthcare, and others. Traditional statistical and deep learning methods struggle to capture complex correlations in urban...\n",
            "\n",
            "    10. **Paper:** Yuan, Xiaoming, 2023, Computing Enabled Urban Traffi...\n",
            "       **Authors:** Yuan, Xiaoming, Chen, Jiahui, Yang, Jiayu et al.\n",
            "       **Year:** 2023, **Times Cited:** 64\n",
            "       **Source:** IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS\n",
            "       **Abstract:** Predicting traffic flow plays an important role in reducing traffic congestion and improving transportation efficiency for smart cities. Traffic Flow Prediction (TFP) in the smart city requires efficient models, highly reliable networks, and data privacy. As traffic data, traffic trajectory can be transformed into a graph representation, so as to mine the spatio-temporal information of the graph for TFP. However, most existing work adopt a central training mode where the privacy problem brought ...\n",
            "\n",
            "\n",
            "   **Suggested Theme:** Prediction, Temporal, Traffic\n",
            "\n",
            "   **Top 20 Keywords:**\n",
            "     - 'prediction': 332\n",
            "     - 'temporal': 322\n",
            "     - 'traffic': 319\n",
            "     - 'learning': 239\n",
            "     - 'network': 228\n",
            "     - 'spatial': 214\n",
            "     - 'flow': 183\n",
            "     - 'graph': 176\n",
            "     - 'time': 154\n",
            "     - 'spatio': 128\n",
            "     - 'networks': 128\n",
            "     - 'neural': 122\n",
            "     - 'our': 112\n",
            "     - 'which': 112\n",
            "     - 'deep': 108\n",
            "     - 'multi': 107\n",
            "     - 'propose': 106\n",
            "     - 'models': 106\n",
            "     - 'real': 99\n",
            "     - 'proposed': 98\n",
            "\n",
            "   **Top 10 Authors:**\n",
            "     - Zheng, Yu: 12 paper(s)/appearance(s)\n",
            "     - Zhang, Junbo: 11 paper(s)/appearance(s)\n",
            "     - Li, Tianrui: 8 paper(s)/appearance(s)\n",
            "     - Liang, Yuxuan: 8 paper(s)/appearance(s)\n",
            "     - Song, Xuan: 7 paper(s)/appearance(s)\n",
            "     - Li, Yong: 5 paper(s)/appearance(s)\n",
            "     - Shibasaki, Ryosuke: 5 paper(s)/appearance(s)\n",
            "     - Fan, Zipei: 5 paper(s)/appearance(s)\n",
            "     - Wang, Hongjun: 4 paper(s)/appearance(s)\n",
            "     - Wang, Senzhang: 4 paper(s)/appearance(s)\n",
            "\n",
            "\n",
            "============================== Detailed Print Summary: Community ID 3 (Size: 20 papers) ==============================\n",
            "\n",
            "   **Temporal Overview:**\n",
            "     - Years Covered: 2007 - 2025\n",
            "     - Median Year: 2018\n",
            "\n",
            "   **Top 10 Papers by Times Cited (with Abstracts):**\n",
            "    1. **Paper:** Fan, Chao, 2017, Longitudinal Analysis of the O...\n",
            "       **Authors:** Fan, Chao, Myint, Soe W., Kaplan, Shai et al.\n",
            "       **Year:** 2017, **Times Cited:** 60\n",
            "       **Source:** REMOTE SENSING\n",
            "       **Abstract:** We quantified the spatio-temporal patterns of land cover/land use (LCLU) change to document and evaluate the daytime surface urban heat island (SUHI) for five hot subtropical desert cities (Beer Sheva, Israel; Hotan, China; Jodhpur, India; Kharga, Egypt; and Las Vegas, NV, USA). Sequential Landsat images were acquired and classified into the USGS 24-category Land Use Categories using object-based image analysis with an overall accuracy of 80% to 95.5%. We estimated the land surface temperature (...\n",
            "\n",
            "    2. **Paper:** Chakraborty, Tc, 2021, islands: A global analysis...\n",
            "       **Authors:** Chakraborty, Tc, Lee, Xuhui, Ermida, Sofia et al.\n",
            "       **Year:** 2021, **Times Cited:** 60\n",
            "       **Source:** REMOTE SENSING OF ENVIRONMENT\n",
            "       **Abstract:** The prescription of surface emissivity (epsilon) strongly controls satellite-derived estimates of land surface temperature (LST). This is particularly important for studying surface urban heat islands (SUHI) since built-up and natural landscapes are known to have distinct epsilon values. Given the small signal associated with the SUHI compared to LST, accurately prescribing urban and rural epsilon would improve our satellite-derived SUHI estimates. Here we test the sensitivity of SUHI to the eps...\n",
            "\n",
            "    3. **Paper:** Rigo, G., 2007, data...\n",
            "       **Authors:** Rigo, G., Parlow, E.\n",
            "       **Year:** 2007, **Times Cited:** 54\n",
            "       **Source:** THEORETICAL AND APPLIED CLIMATOLOGY\n",
            "       **Abstract:** During the Basel Urban Boundary Layer Experiment (BUBBLE) conducted in 2002, micrometeorological in-situ data were collected for different sites using a variety of instruments. This provides a unique data set for urban climate studies. Nevertheless, the spatial distribution of energy and heat fluxes can only be taken into account with remote sensing methods or numerical models. Therefore, multiple satellite images from different platforms (NOAA-AVHRR, MODIS and LANDSAT ETM+) were acquired, proce...\n",
            "\n",
            "    4. **Paper:** Bocher, Erwan, 2018, chain...\n",
            "       **Authors:** Bocher, Erwan, Petit, Gwendall, Bernard, Jeremy et al.\n",
            "       **Year:** 2018, **Times Cited:** 45\n",
            "       **Source:** URBAN CLIMATE\n",
            "       **Abstract:** A growing demand from urban planning services and various research thematics concerns urban fabric characterization. Several projects (such as WUDAPT) are currently lead in the urban climate field to answer this demand. However there is currently a need to propose standardized methods to calculate urban indicators and to automatically classify the urban fabric for any city in the world as well as to propose platforms to share these methods and the associated results. Our contribution answers par...\n",
            "\n",
            "    5. **Paper:** Silva, Humberto R., 2009, Climate...\n",
            "       **Authors:** Silva, Humberto R., Bhardwaj, Rahul, Phelan, Patrick E. et al.\n",
            "       **Year:** 2009, **Times Cited:** 28\n",
            "       **Source:** JOURNAL OF APPLIED METEOROLOGY AND CLIMATOLOGY\n",
            "       **Abstract:** A simple energy balance model is created for use in developing mitigation strategies for the urban heat island effect. The model is initially applied to the city of Phoenix, Arizona. There are six primary contributions to the overall energy balance: incident solar radiation, anthropogenic heat input, conduction heat loss, outgoing evapotranspiration, outgoing convection, and outgoing emitted radiation. Meteorological data are input to the model, which then computes an urban characteristic temper...\n",
            "\n",
            "    6. **Paper:** Abir, Farhan Asaf, 2021, quantifying multivariate contr...\n",
            "       **Authors:** Abir, Farhan Asaf, Ahmmed, Sabbir, Sarker, Soykot Hossain et al.\n",
            "       **Year:** 2021, **Times Cited:** 27\n",
            "       **Source:** HELIYON\n",
            "       **Abstract:** In recent years, the world has shown considerable concerns about environmental degradation accompanied by urban expansion. In terms of size, Bogura is equivalent to most of the major cities in Bangladesh, yet no thermal and ecological assessment has ever been conducted here. This study uses multitemporal Landsat satellite images between 2001 and 2020 to investigate the thermal and ecological conditions of Bogura Sadar (sub-district). Land surface temperature (LST) is obtained from Landsat images...\n",
            "\n",
            "    7. **Paper:** Ramzan, Mohsin, 2022, Temperature and Land Use-Land ...\n",
            "       **Authors:** Ramzan, Mohsin, Saqib, Zulfiqar Ahmad, Hussain, Ejaz et al.\n",
            "       **Year:** 2022, **Times Cited:** 23\n",
            "       **Source:** LAND\n",
            "       **Abstract:** Pakistan has the highest rate of urbanization in South Asia. The climate change effects felt all over the world have become a priority for regulation agencies and governments at global and regional scales with respect assessing and mitigating the rising temperatures in urban areas. This study investigated the temporal variability in urban microclimate in terms of land surface temperature (LST) and its correlation with land use-land cover (LULC) change in Lahore city for prediction of future impa...\n",
            "\n",
            "    8. **Paper:** Jhaldiyal, Alok, 2018, morphology...\n",
            "       **Authors:** Jhaldiyal, Alok, Gupta, Kshama, Gupta, Prasun Kumar et al.\n",
            "       **Year:** 2018, **Times Cited:** 21\n",
            "       **Source:** URBAN CLIMATE\n",
            "       **Abstract:** Urban climate studies crucially depend on various urban morphological parameters. The availability of these parameters assists in understanding wind flow inside urban areas, Urban Heat Island (UHI) phenomenon and also aids in estimation of anthropogenic heat in Numerical Weather Prediction models for improved forecast. Of the two approaches used, micro-meteorological approach is un-suitable for urban applications due to various operational complexities. Morphometric approaches are more feasible ...\n",
            "\n",
            "    9. **Paper:** Shirowzhan, Sara, 2016, Data over Urban Areas...\n",
            "       **Authors:** Shirowzhan, Sara, Lim, Samsung, Trinder, John\n",
            "       **Year:** 2016, **Times Cited:** 19\n",
            "       **Source:** JOURNAL OF SURVEYING ENGINEERING\n",
            "       **Abstract:** Many existing algorithms for light detection and ranging (lidar) data classification are known to perform reliably; however, the automation of the classification of complex urban scenes is still a challenging problem. In this paper, two classification algorithms based on spatial autocorrelation statistics, such as the Local Moran's I and the Getis-Ord Gi*, are proposed. These autocorrelation statistics are computed over sample urban areas, including complex terrain with diverse building characte...\n",
            "\n",
            "    10. **Paper:** Alam, Irtija, 2023, Bangladesh...\n",
            "       **Authors:** Alam, Irtija, Nahar, Kamrun, Morshed, Md Manjur\n",
            "       **Year:** 2023, **Times Cited:** 11\n",
            "       **Source:** HELIYON\n",
            "       **Abstract:** Khulna, the third-largest metropolitan area in Bangladesh, has become a potential site for the polycentric urbanization for multiple mega-projects. Measurement of urban expansion is essential for regulating haphazard growth and achieving effective management. This study aims to quantify and compare the urban expansion pattern of Khulna City Corporation (KCC) and sur-rounding areas' development hotspots. Landsat remote sensing images of 1990, 2000, 2010 and 2020 were used to perform supervised cl...\n",
            "\n",
            "\n",
            "   **Suggested Theme:** Land, Areas, Surface\n",
            "\n",
            "   **Top 20 Keywords:**\n",
            "     - 'land': 32\n",
            "     - 'areas': 31\n",
            "     - 'surface': 30\n",
            "     - 'lst': 27\n",
            "     - 'heat': 26\n",
            "     - 'climate': 23\n",
            "     - 'temperature': 23\n",
            "     - 'area': 21\n",
            "     - 'rural': 21\n",
            "     - 'suhi': 21\n",
            "     - 'cover': 20\n",
            "     - 'effect': 20\n",
            "     - 'expansion': 18\n",
            "     - 'spatial': 17\n",
            "     - 'island': 17\n",
            "     - 'vegetation': 16\n",
            "     - 'between': 15\n",
            "     - 'difference': 15\n",
            "     - 'urbanization': 14\n",
            "     - 'index': 14\n",
            "\n",
            "   **Top 10 Authors:**\n",
            "     - Bocher, Erwan: 1 paper(s)/appearance(s)\n",
            "     - Petit, Gwendall: 1 paper(s)/appearance(s)\n",
            "     - Bernard, Jeremy: 1 paper(s)/appearance(s)\n",
            "     - Palominos, Sylvain: 1 paper(s)/appearance(s)\n",
            "     - Jhaldiyal, Alok: 1 paper(s)/appearance(s)\n",
            "     - Gupta, Kshama: 1 paper(s)/appearance(s)\n",
            "     - Gupta, Prasun Kumar: 1 paper(s)/appearance(s)\n",
            "     - Thakur, Praveen: 1 paper(s)/appearance(s)\n",
            "     - Kumar, Pramod: 1 paper(s)/appearance(s)\n",
            "     - Ma, Xi'na: 1 paper(s)/appearance(s)\n",
            "\n",
            "\n",
            "============================== Detailed Print Summary: Community ID 1 (Size: 8 papers) ==============================\n",
            "\n",
            "   **Temporal Overview:**\n",
            "     - Years Covered: 2006 - 2025\n",
            "     - Median Year: 2018\n",
            "\n",
            "   **Top 10 Papers by Times Cited (with Abstracts):**\n",
            "    1. **Paper:** Zeng, Zhiqiang, 2021, provide decision support for r...\n",
            "       **Authors:** Zeng, Zhiqiang, Yuan, Xiaohui, Liang, Ji et al.\n",
            "       **Year:** 2021, **Times Cited:** 46\n",
            "       **Source:** ENVIRONMENTAL MODELLING & SOFTWARE\n",
            "       **Abstract:** Storm Water Management Model (SWMM), a hydrodynamic rainfall-runoff and urban drainage simulation model, is widely applied in planning, analysis, and design. It is worth mentioning that the hydrological and hydrodynamic simulation functions of SWMM can also provide decision support for real-time urban stormwater management. However, it remains challenging to directly apply traditional SWMM to real-time urban storm water management based on web technology. Here we designed and implemented a web s...\n",
            "\n",
            "    2. **Paper:** Hua, Lizhong, 2017, application associated with ra...\n",
            "       **Authors:** Hua, Lizhong, Shao, Guofan, Zhao, Jingzhu\n",
            "       **Year:** 2017, **Times Cited:** 41\n",
            "       **Source:** INTERNATIONAL JOURNAL OF SUSTAINABLE DEVELOPMENT AND WORLD ECOLOGY\n",
            "       **Abstract:** Urban ecological risk (UER) caused by rapid urbanization means potential threat to urban ecosystem structure, pattern and services. The scales of ecological risk assessment (ERA) have been expanded from individual organisms to watersheds and regions. The types of stressor range from chemical to physical, biological and natural events. However, the application of ERA in urban ecosystems is relatively new. Here, we summarize the progress of urban ERA and propose an explicit framework to illumine f...\n",
            "\n",
            "    3. **Paper:** Jenerette, G. Darrel, 2006, provisioning of urban freshwat...\n",
            "       **Authors:** Jenerette, G. Darrel, Marussich, Wendy A., Newell, Joshua P.\n",
            "       **Year:** 2006, **Times Cited:** 41\n",
            "       **Source:** ECOLOGICAL ECONOMICS\n",
            "       **Abstract:** Two prominent and alternate approaches, ecosystem service valuation and ecological footprints, link the production of ecosystem services with their consumption by societies. An overlapping goal of both approaches is to promote the sustainable use of ecosystem services such that their production rates are not compromised. Yet, little integration of these perspectives and their emphasis on distinct units, dollars and area, has been attempted. We combined these two approaches to better understand v...\n",
            "\n",
            "    4. **Paper:** Bennis, S., 2007, New runoff simulation model fo...\n",
            "       **Authors:** Bennis, S., Crobeddu, E.\n",
            "       **Year:** 2007, **Times Cited:** 24\n",
            "       **Source:** JOURNAL OF HYDROLOGIC ENGINEERING\n",
            "       **Abstract:** This note presents a new runoff simulation model based on the improvement of the rational hydrograph method. This improved rational hydrograph method explicitly considers the contribution of pervious and impervious areas, the time variability of rainfall, the initial abstraction on impervious areas, and the infiltration on pervious areas. Moreover, the traditional rational method appears to be a special case of the proposed rational hydrograph method. A structured procedure is proposed to calibr...\n",
            "\n",
            "    5. **Paper:** Crobeddu, E., 2007, Improved rational hydrograph m...\n",
            "       **Authors:** Crobeddu, E., Bennis, S., Rhouzlane, S.\n",
            "       **Year:** 2007, **Times Cited:** 13\n",
            "       **Source:** JOURNAL OF HYDROLOGY\n",
            "       **Abstract:** This paper presents an improved rational hydrograph method to compute the runoff at the outlet of a small urban catchment. The new formulation, based on the linear system theory, explicitly considers the contributions of pervious and impervious areas, the time variability of rainfall, the initial abstraction on impervious areas and the infiltration on pervious areas. Moreover, the rational method formula appears to be a special case of the proposed rational hydrograph method. A sensitivity analy...\n",
            "\n",
            "    6. **Paper:** Li, Donglai, 2020, Urban Flood...\n",
            "       **Authors:** Li, Donglai, Hou, Jingming, Xia, Junqiang et al.\n",
            "       **Year:** 2020, **Times Cited:** 12\n",
            "       **Source:** FRONTIERS IN EARTH SCIENCE\n",
            "       **Abstract:** Assessing the performance and capability of drainage pipes is of significance for computing urban flooding. However, drainage-pipe data is not available for most urban areas, therefore raising the problem for computing the drainage capability in an approximate way. To resolve this problem, a new type of approach that improves on the existing approach, termed the inlet-drainage approach, is proposed by assuming the drainage effects as a mass subtracted in particular parts, e.g., the area with gul...\n",
            "\n",
            "    7. **Paper:** Chen, Tong, 2025, partitioning techniques and pa...\n",
            "       **Authors:** Chen, Tong, Sun, Jian, Zhang, Zihao et al.\n",
            "       **Year:** 2025, **Times Cited:** 0\n",
            "       **Source:** JOURNAL OF HYDROLOGY\n",
            "       **Abstract:** China has been frequently affected by urban flooding incidents in recent years. Using hydrodynamic models to simulating urban flooding process is an effective measure in flood control. Considerable literatures of hydrodynamic models confine its scope to relatively small areas or low-resolution limited by computing resources and model performance. Relatively less research of HPC in urban flood modeling is conducted. This paper introduces a parallel model based on hydrodynamic principles and MPI, ...\n",
            "\n",
            "    8. **Paper:** Sheng, Zheng, 2025, Real-Time Waterlogging Monitor...\n",
            "       **Authors:** Sheng, Zheng, Chen, Fan, Liu, QiCheng et al.\n",
            "       **Year:** 2025, **Times Cited:** 0\n",
            "       **Source:** WATER RESOURCES MANAGEMENT\n",
            "       **Abstract:** Urban road waterlogging detection is a critical task for smart city management, requiring efficient and accurate solutions. Every year during the heavy rainfall season, urban road waterlogging is a recurring problem that severely impacts traffic operations, causing significant economic losses. This study proposes an edge computing framework that leverages the YOLOv8 model to address these challenges. The model was trained, optimized, and converted for deployment on the RDK X3 edge platform, enab...\n",
            "\n",
            "\n",
            "   **Suggested Theme:** Runoff, Rational, Proposed\n",
            "\n",
            "   **Top 20 Keywords:**\n",
            "     - 'runoff': 16\n",
            "     - 'rational': 15\n",
            "     - 'proposed': 13\n",
            "     - 'hydrograph': 13\n",
            "     - 'time': 12\n",
            "     - 'management': 12\n",
            "     - 'real': 12\n",
            "     - 'era': 11\n",
            "     - 'water': 11\n",
            "     - 'swmm': 11\n",
            "     - 'performance': 10\n",
            "     - 'drainage': 10\n",
            "     - 'ecosystem': 10\n",
            "     - 'waterlogging': 10\n",
            "     - 'areas': 9\n",
            "     - 'improved': 9\n",
            "     - 'web': 9\n",
            "     - 'models': 8\n",
            "     - 'ecological': 8\n",
            "     - 'new': 7\n",
            "\n",
            "   **Top 10 Authors:**\n",
            "     - Bennis, S.: 2 paper(s)/appearance(s)\n",
            "     - Crobeddu, E.: 2 paper(s)/appearance(s)\n",
            "     - Li, Donglai: 1 paper(s)/appearance(s)\n",
            "     - Hou, Jingming: 1 paper(s)/appearance(s)\n",
            "     - Xia, Junqiang: 1 paper(s)/appearance(s)\n",
            "     - Tong, Yu: 1 paper(s)/appearance(s)\n",
            "     - Yang, Dong: 1 paper(s)/appearance(s)\n",
            "     - Zhang, Dawei: 1 paper(s)/appearance(s)\n",
            "     - Gao, Xujun: 1 paper(s)/appearance(s)\n",
            "     - Chen, Tong: 1 paper(s)/appearance(s)\n",
            "\n",
            "\n",
            "============================== End of Detailed Print Summaries ==============================\n"
          ]
        }
      ],
      "source": [
        "# Cell 9: Detailed Community Summaries (print output version - before HTML table)\n",
        "# This cell is an adaptation of the previous cell 9 logic if you want a text-based detailed dump.\n",
        "# The main HTML output is generated by the next cell (formerly cell 10).\n",
        "# For brevity, I will keep this similar to the original cell 9's structure,\n",
        "# but note that the real \"enhanced\" output is in the next cell.\n",
        "\n",
        "# Helper function (can be merged with the one in the next cell if identical)\n",
        "def get_node_data_for_detailed_print_analysis(graph, node_id):\n",
        "    if node_id not in graph:\n",
        "        return {\"id\": node_id, \"error\": \"Node not found in graph\"}\n",
        "    node_attrs = graph.nodes[node_id]\n",
        "    authors_list = node_attrs.get('authors_full', [])\n",
        "    if not authors_list or not any(authors_list): authors_list = node_attrs.get('authors_short', [])\n",
        "\n",
        "    title_text = node_attrs.get('title', '')\n",
        "    abstract_text = node_attrs.get('abstract', '') # Ensure abstract is fetched\n",
        "    keywords_de_list = node_attrs.get('keywords_de', [])\n",
        "    keywords_id_list = node_attrs.get('keywords_id', [])\n",
        "    keywords_de_str = \" \".join(keywords_de_list if isinstance(keywords_de_list, list) else [str(keywords_de_list)])\n",
        "    keywords_id_str = \" \".join(keywords_id_list if isinstance(keywords_id_list, list) else [str(keywords_id_list)])\n",
        "    text_for_keywords = f\"{title_text} {abstract_text} {keywords_de_str} {keywords_id_str}\"\n",
        "\n",
        "    year_str_val = node_attrs.get('year', '0')\n",
        "    try: year_int_val = int(float(year_str_val))\n",
        "    except ValueError: year_int_val = 0\n",
        "\n",
        "    return {\n",
        "        \"id\": node_id,\n",
        "        \"label\": node_attrs.get('label', str(node_id)),\n",
        "        \"title\": title_text,\n",
        "        \"abstract\": abstract_text, # Include abstract\n",
        "        \"text_for_keywords\": text_for_keywords,\n",
        "        \"year_str\": year_str_val, # Keep original year string\n",
        "        \"year_int\": year_int_val, # Integer year\n",
        "        \"times_cited\": int(node_attrs.get('times_cited', 0)),\n",
        "        \"authors\": authors_list, # Full names\n",
        "        \"source\": node_attrs.get('source', 'N/A'),\n",
        "        \"degree_centrality\": float(node_attrs.get('degree_centrality', 0.0)),\n",
        "        \"betweenness_centrality\": float(node_attrs.get('betweenness_centrality', 0.0)),\n",
        "        \"eigenvector_centrality\": float(node_attrs.get('eigenvector_centrality', 0.0)),\n",
        "        \"community_id\": node_attrs.get('community_id', -1)\n",
        "    }\n",
        "\n",
        "\n",
        "if 'partition_new' not in locals() or not isinstance(partition_new, dict) or not partition_new:\n",
        "    print(\"ERROR: 'partition_new' dictionary not found or empty for detailed print analysis.\")\n",
        "elif 'G_main_cc_new' not in locals() or not hasattr(G_main_cc_new, 'nodes') or G_main_cc_new.number_of_nodes() == 0:\n",
        "    print(\"ERROR: 'G_main_cc_new' graph not found or empty for detailed print analysis.\")\n",
        "else:\n",
        "    community_sizes = Counter(partition_new.values())\n",
        "    # Analyze top N (NUMBER_OF_TOP_ITEMS_TO_SHOW, now 10) largest communities\n",
        "    top_communities_for_print = community_sizes.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW)\n",
        "\n",
        "    if not top_communities_for_print:\n",
        "        print(\"No communities found for detailed print analysis.\")\n",
        "    else:\n",
        "        top_ids_for_print = [item[0] for item in top_communities_for_print]\n",
        "        print(f\"Generating Detailed Print Summaries for Top {len(top_ids_for_print)} Communities: {top_ids_for_print}\\n\")\n",
        "\n",
        "        all_communities_print_summary_data = []\n",
        "\n",
        "        for comm_id in top_ids_for_print:\n",
        "            community_size = community_sizes[comm_id]\n",
        "            community_data_print = { # For structured data, similar to HTML table version\n",
        "                \"id\": comm_id, \"size\": community_size, \"papers\": [],\n",
        "                \"top_keywords\": [], \"suggested_theme_title\": \"N/A\",\n",
        "                \"pillar_papers\": [], \"top_by_times_cited\": [], \"top_by_betweenness\": [],\n",
        "                \"top_by_degree\": [], \"top_authors\": [], \"top_sources\": [], \"temporal_overview\": {}\n",
        "            }\n",
        "            print(f\"\\n\\n{'='*30} Detailed Print Summary: Community ID {comm_id} (Size: {community_size} papers) {'='*30}\")\n",
        "\n",
        "            community_node_ids = [node_id for node_id, c_id in partition_new.items() if c_id == comm_id]\n",
        "            community_papers_details_print = []\n",
        "            paper_years_in_community_print = []\n",
        "\n",
        "            for node_id in community_node_ids:\n",
        "                paper_data = get_node_data_for_detailed_print_analysis(G_main_cc_new, node_id)\n",
        "                if \"error\" not in paper_data:\n",
        "                     community_papers_details_print.append(paper_data)\n",
        "                     if paper_data['year_int'] > 0:\n",
        "                         paper_years_in_community_print.append(paper_data['year_int'])\n",
        "\n",
        "            if not community_papers_details_print:\n",
        "                print(\"  No valid paper data collected for this community.\")\n",
        "                all_communities_print_summary_data.append(community_data_print)\n",
        "                continue\n",
        "\n",
        "            community_data_print[\"papers\"] = community_papers_details_print\n",
        "\n",
        "            # --- Temporal Overview ---\n",
        "            if paper_years_in_community_print:\n",
        "                to = {\n",
        "                    \"min_year\": int(np.min(paper_years_in_community_print)) if paper_years_in_community_print else 'N/A',\n",
        "                    \"max_year\": int(np.max(paper_years_in_community_print)) if paper_years_in_community_print else 'N/A',\n",
        "                    \"median_year\": int(np.median(paper_years_in_community_print)) if paper_years_in_community_print else 'N/A',\n",
        "                    \"num_papers_with_year\": len(paper_years_in_community_print)\n",
        "                }\n",
        "                community_data_print[\"temporal_overview\"] = to\n",
        "                print(\"\\n   **Temporal Overview:**\")\n",
        "                print(f\"     - Years Covered: {to.get('min_year', 'N/A')} - {to.get('max_year', 'N/A')}\")\n",
        "                print(f\"     - Median Year: {to.get('median_year', 'N/A')}\")\n",
        "\n",
        "            # --- Top Papers by Times Cited (with Abstracts) ---\n",
        "            community_data_print[\"top_by_times_cited\"] = sorted(community_papers_details_print, key=lambda x: x['times_cited'], reverse=True)[:NUMBER_OF_TOP_ITEMS_TO_SHOW]\n",
        "            print(f\"\\n   **Top {NUMBER_OF_TOP_ITEMS_TO_SHOW} Papers by Times Cited (with Abstracts):**\")\n",
        "            if community_data_print[\"top_by_times_cited\"]:\n",
        "                for i, paper in enumerate(community_data_print[\"top_by_times_cited\"]):\n",
        "                    print(f\"    {i+1}. **Paper:** {paper['label']}\")\n",
        "                    authors_display = \", \".join(paper.get('authors', ['N/A'])[:3])\n",
        "                    if len(paper.get('authors', [])) > 3: authors_display += \" et al.\"\n",
        "                    print(f\"       **Authors:** {authors_display}\")\n",
        "                    print(f\"       **Year:** {paper['year_str']}, **Times Cited:** {paper['times_cited']}\")\n",
        "                    print(f\"       **Source:** {paper['source']}\")\n",
        "                    abstract_content = paper.get('abstract', 'No abstract available.')\n",
        "                    if not abstract_content or not abstract_content.strip(): abstract_content = \"No abstract available.\"\n",
        "                    print(f\"       **Abstract:** {abstract_content[:500]}...\\n\")\n",
        "            else:\n",
        "                print(\"     - N/A\")\n",
        "\n",
        "            # --- Keyword Extraction ---\n",
        "            all_text_content = [p['text_for_keywords'] for p in community_papers_details_print if p['text_for_keywords']]\n",
        "            comm_words = []\n",
        "            for text in all_text_content:\n",
        "                words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
        "                comm_words.extend([w for w in words if w not in STOPWORDS and len(w) > 2])\n",
        "            keyword_counts_print = Counter(comm_words)\n",
        "            community_data_print[\"top_keywords\"] = keyword_counts_print.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW * 2)\n",
        "            if community_data_print[\"top_keywords\"]:\n",
        "                num_kw_title = min(3, len(community_data_print[\"top_keywords\"]))\n",
        "                community_data_print[\"suggested_theme_title\"] = \", \".join([kw[0].capitalize() for kw in community_data_print[\"top_keywords\"][:num_kw_title]])\n",
        "            print(f\"\\n   **Suggested Theme:** {community_data_print['suggested_theme_title']}\")\n",
        "            print(f\"\\n   **Top {NUMBER_OF_TOP_ITEMS_TO_SHOW * 2} Keywords:**\")\n",
        "            for keyword, count in community_data_print[\"top_keywords\"]: print(f\"     - '{keyword}': {count}\")\n",
        "\n",
        "            # --- Top Authors ---\n",
        "            all_auth = []\n",
        "            for p in community_papers_details_print:\n",
        "                if p.get('authors'): all_auth.extend(p['authors'])\n",
        "            author_counts_print = Counter(all_auth)\n",
        "            community_data_print[\"top_authors\"] = author_counts_print.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW)\n",
        "            print(f\"\\n   **Top {NUMBER_OF_TOP_ITEMS_TO_SHOW} Authors:**\") # Now shows 10\n",
        "            for author, count in community_data_print[\"top_authors\"]: print(f\"     - {author}: {count} paper(s)/appearance(s)\")\n",
        "\n",
        "            # Add other rankings (betweenness, degree, sources) if desired for print summary\n",
        "            # community_data_print[\"top_by_betweenness\"] = sorted(community_papers_details_print, key=lambda x: x['betweenness_centrality'], reverse=True)[:NUMBER_OF_TOP_ITEMS_TO_SHOW]\n",
        "            # print(f\"\\n   **Top {NUMBER_OF_TOP_ITEMS_TO_SHOW} Papers by Betweenness Centrality:**\")\n",
        "            # for i, paper in enumerate(community_data_print[\"top_by_betweenness\"]): print(f\"    {i+1}. Betw: {paper['betweenness_centrality']:.4f} | {paper['label']}\")\n",
        "\n",
        "            all_communities_print_summary_data.append(community_data_print)\n",
        "        print(f\"\\n\\n{'='*30} End of Detailed Print Summaries {'='*30}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "TSPwWEG7yYeh",
        "outputId": "efc5d657-2e82-40a3-ffab-9c536cfa4c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================== HTML Summary Table for Top 5 Communities ==============================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Community ID</th>\n",
              "      <th>Size (Papers)</th>\n",
              "      <th>Suggested Theme</th>\n",
              "      <th>Median Year</th>\n",
              "      <th>Top Keywords (Uni)</th>\n",
              "      <th>Top Bi-grams</th>\n",
              "      <th>Pillar Paper(s)</th>\n",
              "      <th>Top Author(s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>338</td>\n",
              "      <td>Food, Access, Desert</td>\n",
              "      <td>2019</td>\n",
              "      <td>food (3260); access (819); desert (698); deserts (555); health (484)</td>\n",
              "      <td>food desert (674); food deserts (512); food access (278)</td>\n",
              "      <td>Farber, Steven, 2014, Temporal variability in transi......</td>\n",
              "      <td>Dubowitz, Tamara (27); Beckman, Robin (15); Collins, Rebecca L. (13)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>329</td>\n",
              "      <td>Smart, Time, Which</td>\n",
              "      <td>2020</td>\n",
              "      <td>smart (313); time (246); which (243); our (211); network (191)</td>\n",
              "      <td>internet things (77); real world (61); human mobility (55)</td>\n",
              "      <td>Zheng, Yu, 2014, Urban Computing: Concepts, Met......; Castro, Pablo Samuel, 2013, From Taxi GPS Traces to Social......</td>\n",
              "      <td>Zheng, Yu (14); Li, Tianrui (6); Li, Yanhua (6)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>137</td>\n",
              "      <td>Prediction, Temporal, Traffic</td>\n",
              "      <td>2023</td>\n",
              "      <td>prediction (332); temporal (322); traffic (319); learning (239); network (228)</td>\n",
              "      <td>spatio temporal (128); spatial temporal (96); deep learning (78)</td>\n",
              "      <td>Ali, Ahmad, 2022, for citywide traffic flows pre......; Peng, Hao, 2020, flow forecasting......</td>\n",
              "      <td>Zheng, Yu (12); Zhang, Junbo (11); Li, Tianrui (8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>Land, Areas, Surface</td>\n",
              "      <td>2018</td>\n",
              "      <td>land (32); areas (31); surface (30); lst (27); heat (26)</td>\n",
              "      <td>heat island (17); surface temperature (11); land cover (11)</td>\n",
              "      <td>Fan, Chao, 2017, Longitudinal Analysis of the O......; Chakraborty, Tc, 2021, islands: A global analysis......</td>\n",
              "      <td>Bocher, Erwan (1); Petit, Gwendall (1); Bernard, Jeremy (1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Runoff, Rational, Proposed</td>\n",
              "      <td>2018</td>\n",
              "      <td>runoff (16); rational (15); proposed (13); hydrograph (13); time (12)</td>\n",
              "      <td>rational hydrograph (13); real time (10); improved rational (9)</td>\n",
              "      <td>Zeng, Zhiqiang, 2021, provide decision support for r......; Hua, Lizhong, 2017, application associated with ra......</td>\n",
              "      <td>Bennis, S. (2); Crobeddu, E. (2); Li, Donglai (1)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================== End of All Community HTML Summary Analysis ==============================\n"
          ]
        }
      ],
      "source": [
        "# Cell 10: Deeper Analysis & HTML Summary Table (Main Output Cell, adapted from original cell 10)\n",
        "import collections # Already imported but good for clarity\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Helper function (ensure it's consistent or use the one from Cell 9 if identical)\n",
        "def get_node_data_for_html_summary(graph, node_id_from_graph):\n",
        "    if node_id_from_graph not in graph:\n",
        "        # print(f\"Error: Node {node_id_from_graph} not found in graph for HTML summary.\")\n",
        "        return {\"id\": node_id_from_graph, \"error\": \"Node not found in graph\"}\n",
        "    node_attrs = graph.nodes[node_id_from_graph]\n",
        "\n",
        "    # Prioritize full author names from 'authors_full', fallback to 'authors_short'\n",
        "    authors_list_final = node_attrs.get('authors_full', [])\n",
        "    if not authors_list_final or not any(authors_list_final): # Check if empty or list of Nones/empty strings\n",
        "        authors_list_final = node_attrs.get('authors_short', [])\n",
        "\n",
        "    title_text = node_attrs.get('title', 'N/A')\n",
        "    abstract_text = node_attrs.get('abstract', '')\n",
        "    keywords_de_list = node_attrs.get('keywords_de', [])\n",
        "    keywords_id_list = node_attrs.get('keywords_id', [])\n",
        "    keywords_de_str = \" \".join(keywords_de_list if isinstance(keywords_de_list, list) else [str(keywords_de_list)])\n",
        "    keywords_id_str = \" \".join(keywords_id_list if isinstance(keywords_id_list, list) else [str(keywords_id_list)])\n",
        "    text_for_keywords = f\"{title_text} {abstract_text} {keywords_de_str} {keywords_id_str}\"\n",
        "\n",
        "    year_str_val = node_attrs.get('year', '0')\n",
        "    try: year_int_val = int(float(year_str_val))\n",
        "    except ValueError: year_int_val = 0\n",
        "\n",
        "    return {\n",
        "        \"id\": node_id_from_graph,\n",
        "        \"label\": node_attrs.get('label', str(node_id_from_graph)), # Label already updated\n",
        "        \"title\": title_text,\n",
        "        \"abstract\": abstract_text,\n",
        "        \"text_for_keywords\": text_for_keywords.strip(),\n",
        "        \"year_str\": year_str_val,\n",
        "        \"year_int\": year_int_val,\n",
        "        \"times_cited\": int(node_attrs.get('times_cited', 0)),\n",
        "        \"authors\": authors_list_final, # << ENSURED FULL NAMES\n",
        "        \"source\": node_attrs.get('source', 'N/A'),\n",
        "        \"degree_centrality\": float(node_attrs.get('degree_centrality', 0.0)),\n",
        "        \"betweenness_centrality\": float(node_attrs.get('betweenness_centrality', 0.0)),\n",
        "        \"eigenvector_centrality\": float(node_attrs.get('eigenvector_centrality', 0.0)),\n",
        "        \"community_id\": node_attrs.get('community_id', -1)\n",
        "    }\n",
        "\n",
        "def generate_ngrams_for_summary(text, n, stopwords_list): # Renamed to avoid conflict\n",
        "    words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n",
        "    filtered_words = [word for word in words if word not in stopwords_list]\n",
        "    if not filtered_words or len(filtered_words) < n: return []\n",
        "    ngrams = zip(*[filtered_words[i:] for i in range(n)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]\n",
        "\n",
        "# --- Main Analysis Loop for Top N Communities ---\n",
        "if 'partition_new' not in locals() or not isinstance(partition_new, dict) or not partition_new:\n",
        "    print(\"ERROR: 'partition_new' not found for HTML summary. Run community detection.\")\n",
        "elif 'G_main_cc_new' not in locals() or not hasattr(G_main_cc_new, 'nodes') or G_main_cc_new.number_of_nodes() == 0:\n",
        "    print(\"ERROR: 'G_main_cc_new' graph not found for HTML summary.\")\n",
        "else:\n",
        "    community_sizes = Counter(partition_new.values())\n",
        "    if 'NUMBER_OF_TOP_ITEMS_TO_SHOW' not in locals(): NUMBER_OF_TOP_ITEMS_TO_SHOW = 10 # Default\n",
        "    if 'STOPWORDS' not in locals(): STOPWORDS = set([\"the\", \"a\", \"is\"]) # Minimal default\n",
        "\n",
        "    # Analyze Top N (e.g., 10) communities\n",
        "    top_N_communities_list = community_sizes.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW) # << MODIFIED to take N\n",
        "\n",
        "    if not top_N_communities_list:\n",
        "        print(\"No communities found to analyze for HTML summary.\")\n",
        "    else:\n",
        "        top_N_community_ids = [item[0] for item in top_N_communities_list]\n",
        "        # print(f\"Performing HTML summary analysis on Top {len(top_N_community_ids)} communities: {top_N_community_ids}\\n\") # Verbose print\n",
        "\n",
        "        all_communities_html_summary_data = []\n",
        "\n",
        "        for comm_id in top_N_community_ids:\n",
        "            community_size = community_sizes[comm_id]\n",
        "            # Verbose print for each community being processed for the table\n",
        "            # print(f\"\\n--- Processing Community ID: {comm_id} (Size: {community_size} papers) for HTML Table ---\")\n",
        "\n",
        "            current_community_papers_details_html = []\n",
        "            paper_years_in_community_html = []\n",
        "            community_node_ids_html = [node_id for node_id, c_id in partition_new.items() if c_id == comm_id]\n",
        "\n",
        "            for node_id in community_node_ids_html:\n",
        "                paper_data = get_node_data_for_html_summary(G_main_cc_new, node_id)\n",
        "                if \"error\" not in paper_data:\n",
        "                     current_community_papers_details_html.append(paper_data)\n",
        "                     if paper_data['year_int'] > 0:\n",
        "                         paper_years_in_community_html.append(paper_data['year_int'])\n",
        "\n",
        "            community_summary_for_table = {\n",
        "                \"Community ID\": comm_id, \"Size (Papers)\": community_size,\n",
        "                \"Suggested Theme\": \"N/A\", \"Top Keywords (Uni)\": \"N/A\",\n",
        "                \"Top Bi-grams\": \"N/A\", \"Pillar Paper(s)\": \"N/A\",\n",
        "                \"Top Author(s)\": \"N/A\", \"Median Year\": \"N/A\"\n",
        "            }\n",
        "\n",
        "            if not current_community_papers_details_html:\n",
        "                # print(f\"  No valid paper data for Community {comm_id} for HTML table.\")\n",
        "                all_communities_html_summary_data.append(community_summary_for_table) # Add placeholder\n",
        "                continue\n",
        "\n",
        "            if paper_years_in_community_html:\n",
        "                community_summary_for_table[\"Median Year\"] = int(np.median(paper_years_in_community_html))\n",
        "\n",
        "            full_text_for_comm_html = \" \".join([p['text_for_keywords'] for p in current_community_papers_details_html if p['text_for_keywords']])\n",
        "            if full_text_for_comm_html.strip():\n",
        "                unigrams_html = generate_ngrams_for_summary(full_text_for_comm_html, 1, STOPWORDS)\n",
        "                unigram_counts_html = Counter(unigrams_html)\n",
        "                top_unigrams_html = unigram_counts_html.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW) # Use N for basis\n",
        "                community_summary_for_table[\"Top Keywords (Uni)\"] = \"; \".join([f\"{ug[0]} ({ug[1]})\" for ug in top_unigrams_html[:5]]) # Show top 5 in table\n",
        "                if top_unigrams_html: community_summary_for_table[\"Suggested Theme\"] = \", \".join([kw[0].capitalize() for kw in top_unigrams_html[:3]])\n",
        "\n",
        "                bigrams_html = generate_ngrams_for_summary(full_text_for_comm_html, 2, STOPWORDS)\n",
        "                bigram_counts_html = Counter(bigrams_html)\n",
        "                top_bigrams_html = bigram_counts_html.most_common(NUMBER_OF_TOP_ITEMS_TO_SHOW)\n",
        "                community_summary_for_table[\"Top Bi-grams\"] = \"; \".join([f\"{bg[0]} ({bg[1]})\" for bg in top_bigrams_html[:3]]) # Show top 3 in table\n",
        "\n",
        "            all_authors_comm_html = []\n",
        "            for p in current_community_papers_details_html:\n",
        "                if p.get('authors'): all_authors_comm_html.extend(p['authors']) # authors are now full names\n",
        "            author_counts_comm_html = Counter(all_authors_comm_html)\n",
        "            # Show top 3 authors in the table summary, derived from top N\n",
        "            top_authors_for_table = author_counts_comm_html.most_common(min(3, len(author_counts_comm_html)))\n",
        "            community_summary_for_table[\"Top Author(s)\"] = \"; \".join([f\"{auth[0]} ({auth[1]})\" for auth in top_authors_for_table])\n",
        "\n",
        "\n",
        "            # Pillar Paper Identification for table\n",
        "            top_cited_html = sorted(current_community_papers_details_html, key=lambda x: x['times_cited'], reverse=True)\n",
        "            top_betweenness_html = sorted(current_community_papers_details_html, key=lambda x: x['betweenness_centrality'], reverse=True)\n",
        "\n",
        "            # Consider broader pool for pillar candidacy, e.g. top 2*N\n",
        "            pool_size = NUMBER_OF_TOP_ITEMS_TO_SHOW * 2\n",
        "            top_cited_ids_html = {p['id'] for p in top_cited_html[:pool_size]}\n",
        "            top_betweenness_ids_html = {p['id'] for p in top_betweenness_html[:pool_size]}\n",
        "            pillar_ids_html = top_cited_ids_html.intersection(top_betweenness_ids_html)\n",
        "\n",
        "            pillar_papers_for_table_list = []\n",
        "            if pillar_ids_html:\n",
        "                pillar_papers_for_table_list = sorted(\n",
        "                    [p for p in current_community_papers_details_html if p['id'] in pillar_ids_html],\n",
        "                    key=lambda x: x['times_cited'], reverse=True\n",
        "                )\n",
        "            else: # Fallback to top cited if no intersection\n",
        "                pillar_papers_for_table_list = top_cited_html[:2] # Show top 2 cited as fallback \"pillar\"\n",
        "\n",
        "            # Show 1 or 2 pillar papers in the table using their labels (labels now have full first author name)\n",
        "            community_summary_for_table[\"Pillar Paper(s)\"] = \"; \".join([p['label'][:70]+\"...\" for p in pillar_papers_for_table_list[:2]])\n",
        "\n",
        "\n",
        "            all_communities_html_summary_data.append(community_summary_for_table)\n",
        "            # print(f\"--- Done processing Community ID: {comm_id} for HTML Table ---\")\n",
        "\n",
        "\n",
        "        # --- Create and Display Summary Table ---\n",
        "        print(f\"\\n\\n{'='*30} HTML Summary Table for Top {len(top_N_community_ids)} Communities {'='*30}\")\n",
        "        summary_df_html = pd.DataFrame(all_communities_html_summary_data)\n",
        "\n",
        "        columns_for_html_table = [\n",
        "            \"Community ID\", \"Size (Papers)\", \"Suggested Theme\",\n",
        "            \"Median Year\", \"Top Keywords (Uni)\", \"Top Bi-grams\",\n",
        "            \"Pillar Paper(s)\", \"Top Author(s)\"\n",
        "        ]\n",
        "        display_cols_html = [col for col in columns_for_html_table if col in summary_df_html.columns]\n",
        "\n",
        "        if not summary_df_html.empty:\n",
        "            pd.set_option('display.max_colwidth', 200)\n",
        "            pd.set_option('display.width', 1000)\n",
        "            display(HTML(summary_df_html[display_cols_html].to_html(index=False, escape=False))) # escape=False to render HTML if any\n",
        "        else:\n",
        "            print(\"No summary data to display in HTML table.\")\n",
        "\n",
        "        print(f\"\\n\\n{'='*30} End of All Community HTML Summary Analysis {'='*30}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PzEMutiCyb32"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
